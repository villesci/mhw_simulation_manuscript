---
title: "Marine Heatwave Simulation Analysis"
author: "Andrew Villeneuve"
date: "2024-01-12"
output: html_document
bibliography: references.bib
---

# Data analysis introduction

The below analysis creates all figures in Villeneuve and White 2024 MHW simulation paper. The document can be knitted to reproduce the entire analysis. All chunks of this markdown can be run as well, but certain chunks are computationally intensive and can take many hours to complete. These time-consuming chunks are labelled. In key places, we have saved .RDs data files of computational outputs at strategic checkpoints to allow for rapid knitting of the document. These .RDs files are included in the repository for convenience, but are not included in github due to size restrictions.

Two exterior R files are called to define functions used in this analysis. They are as follows:

-   hour_fxns_heatwaveR.R - This file contains ad hoc functions drawn from the heatwaveR package [@schlegel2018]. We edited these functions for our own use to allow for input of hourly data.
-   Thermal_landscape_functions.R - This file contains ad hoc functions drawn from @rezende2020 to calculate static thermal tolerance landscapes and calculate survival over variable temperature time series using a dynamic thermal tolerance model. We edited these functions to incorporate the concept of critical temperature @jørgensen2021 , the temperature at which temperature stress starts to become lethal.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(ggplot2)
require(beepr)
require(purrr)
require(ggridges)
require(parallel)
require(foreach)
require(ggforce)
require(data.table)
require(zoo)
require(cowplot)
require(doParallel)
require(rlang)
require(reshape2)
require(heatwaveR)
require(scico)
require(ggside)
require(metR)
require(ggpubr)
require(terra)
require(SpatialTools)


options(scipen=999)

source("Thermal_landscape_functions.R")
source("hour_fxns_heatwaveR.R")

```

# A function for constructing all possible MHWs from a set of parameters

The first step in this project is to create a function that allows for the construction of all possible MHWs from a range of values for each parameter (magnitude, duration, and rate of onset). For rate of onset, we use duration of onset instead of slope itself, as slope is dependent on magnitude of each event.

Below, we set up the range of parameters. All times must be in minutes, all temperatures are in degrees Celsius.

```{r,echo=T}
magnitude_min<-0.01 #0.01 degree minimum magnitude. Analysis does not accept 0 value
magnitude_max<-8.01 #8 degree duration max. This is in agreement with observed values above climatology across multiple major MHW events
duration_min<-60*1 #one hour MHW min  Here, we differ from other definitions (Hobday et al. 2016) that set minimum values of 5 days for a MHW event. For intertidal organisms, a few hours of extreme heat during low tide during an atmospheric heatwave may cause mortality and should be considered from an ecophysiological perspective. 
duration_max<-24*30*60+60*1 # 30 day MHW max - MHWs can commonly last multiple days, weeks, or months. However, for the sake of this initial analysis, we reduce that to three day for speed of calculation.Note that this is technically 30 days plus one hour, to keep intervals between durations the same. 

magnitude_inc<-0.5 # magnitudes given in 0.5 degree increments 
duration_inc<-24*60 #durations given in 24 hour increments (MUST be in minutes)

```

Now, we can set up the function that creates all possible plateau possibilities from this range of parameters. Note that you must change where the R data file (.RDs) are saved - here, I save them in my personal onedrive folder due to space restrictions on github.

Note that the function below allows for manipulating the slope of MHWs with a slope_inc parameter. The rest of the markdown analysis assumes no change in slope, and so we present this portion of the function here for future reference only.

```{r,echo=F,include=F}


MHW_tri<-function(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc,slope_inc){
  
  #sequence of magnitudes
  mag_seq<-seq(magnitude_min,magnitude_max,by = magnitude_inc)
  
  #sequence of duration (in minutes)
  dur_seq<-seq(duration_min,duration_max,by = duration_inc)
  
  if (missing(slope_inc)){

  #create an expanded dataframe of all possible parameter combinations. 
  
  expanded<-data.frame(expand.grid('mag_seq'=mag_seq,'dur_seq'=dur_seq))
  } else{
  slope_seq<-seq(0.0001,6/360,by=slope_inc)
  expanded<-data.frame(expand.grid('mag_seq'=mag_seq,'dur_seq'=dur_seq,'slope_seq'=slope_seq)) # if we want to control slope
  }
  
  

 

  #create empty matrix to store results
  mag_dur_tri <- vector("list", length(mag_seq))
  
  #single loop to create triangles for each row in the expanded dataframe, encapsulating all possible parameters  
  for (i in 1:nrow(expanded)){
    magnitude<-as.numeric(expanded[i,1])
    hw_length<-expanded[i,2] #duration
    #rising_slope<-expanded[i,3] if we vary slope
    rising_slope<-magnitude/(hw_length/2)
    #create df of dates and numerical sequence
    
    rising_length<-magnitude/rising_slope
    falling_length<-hw_length-rising_length
    if (is.na(rising_length) || is.na(hw_length)) {
      print("Debug: Missing value in rising_length or hw_length")
    #add ifelse to remove unlikely initial slope values
    } else if(rising_length>=hw_length){#if rising portion is longer than entire mhw duration
      z<-data.frame("timestep"=NA,"value"=NA,"magnitude"=magnitude,"duration"=hw_length,"rising_slope"=rising_slope,"falling_slope"=NA,"area"=NA,"mean_i"=NA,"hdd"=NA)
    } else {
    falling_slope<-(-rising_slope)
    #dataframes of rising falling points
    rising_seq<-data.frame("timestep"=seq(1,floor(max(rising_length)),by=1))
    falling_seq<-data.frame("timestep"=seq(from=floor(max(rising_length))+1,to=hw_length,by = 1))
    
    rising_seq$value<-rising_seq$timestep*rising_slope
    falling_seq$value<-(falling_seq$timestep*falling_slope)+(max(rising_length)*magnitude/nrow(falling_seq))+magnitude
    
    #apply values

    z<-rbind(rising_seq,falling_seq)
    z$reps<-i
    z$magnitude<-magnitude
    z$duration<-hw_length
    z$rising_slope<-rising_slope
    z$falling_slope<-falling_slope
    z$area<- magnitude*hw_length/2
    z$mean_i<-mean(z$value)
    #heating degree days
    #first, create a column of day 
    if(hw_length<1440){
      z$unique_day<-hw_length
    }else{
    z$unique_day<-(z$timestep-1)%/%1440+1
    }
  
    hdd_tib<-z%>%group_by(unique_day)%>%summarize(mean_t=mean(value))%>%summarize(output=sum(mean_t))
    z$hdd<-hdd_tib$output
    }

    
    mag_dur_tri[[i]] <- z
    }
  
  boundoutput_tri<-bind_rows(mag_dur_tri,.id="reps") #from matrix to data.frame
  boundoutput_tri$reps<-as.numeric(boundoutput_tri$reps)
  saveRDS(boundoutput_tri,"data/boundoutput_tri.RDs") #saves file to onedrive due to space restrictions in github. Can be silenced. 
  
  return(ggplot(data=boundoutput_tri,aes(x=timestep,y=value,group=reps,color=reps))+geom_line()+ theme(legend.position="none")+scale_color_viridis_c())
  
  }



```

Here, we can see the resulting triangles from our range of parameters.

```{r,echo=F,eval=F}
####TIME CONSUMING####
system.time(tri_output<-MHW_tri(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc))

#tri_output
```

```{r,echo=F,warning=F}
#read in data
tri_outputme<-readRDS('data/boundoutput_tri.RDs')

  
tri_data<-tri_outputme
tri_data$duration<-tri_data$duration/60 #convert to hours for plotting

tri_data$label<-paste(tri_data$magnitude, "°C", sep = "")

ggplot(data=tri_data,aes(x=timestep/60,y=value,group=reps,color=duration))+geom_line()+ theme(legend.position="none")+scale_color_viridis_c(option="magma")+facet_wrap(label~.)+theme_classic()+ylab("Magnitude (°C)")+xlab("Duration (hours)")+labs(color="Duration (hours)")


ggsave(path = "result_figs/supp",filename="allmhws.tif", device='tiff', dpi=300,width=6,height=4,units="in")

```

# Simulating annual time series

Now that we have simulated MHW triangles, we need to add these on top of a typical temperature time series for a given location. First, let's simulate one year of data using a sine wave, then add oceanographic, fixed baseline categories of MHWs [@schlegel2018, @hobday2018].

```{r,echo=F,warning=F,include=F}
## function for creating sine wave
##function from user beckmw https://www.r-bloggers.com/2017/04/predicting-tides-in-r/
waves <- function(date_start,date_end, alpha = 0, beta = 1, freq = 24, phi = 0){
  
  start <- as.POSIXct(date_start)
  end<-as.POSIXct(date_end)
  x <- seq(start, end, by = 60 * 1)
  
  
  # timestep per hour
  time_step <- 60 / unique(diff(x))
  # set phi as difference in hours from start of time_in
  phi <- min(x) + phi * 3600
  phi<- as.numeric(difftime(phi, min(x)))
  phi <- phi / time_step
  # get input values to cos func
  in_vals <- seq(0, length(x), length = length(x))
  in_vals <- in_vals / time_step
  in_vals <- 2 * pi * in_vals * 1 / freq
  # wave
  y <- alpha + beta * sin((in_vals + phi)-(pi*.75))
  df<-data.frame("vals"=y,"datetime"=x)
  return(df)
}
```

```{r,include=F,eval=F}
####TIME CONSUMING####

year_out<-waves('2022-01-01','2022-12-31',alpha=12,beta=14,freq=365*24)

#list of range parameters
alpha_list<-c(12.25,12.75,13.5)
merged_temp_tri_alphas<-vector("list",length=length(alpha_list))

system.time(
for (xx in 1:length(alpha_list)){
  year_thresh<-waves('2022-01-01','2022-12-31',alpha=alpha_list[xx],beta=14,freq=365*24)

  
  clim<-data.frame("hoy"=lubridate::hour(year_out$datetime) + (lubridate::yday(year_out$datetime) - 1) * 24,
                  "doy"=lubridate::yday(year_out$datetime),
                  "t"=year_out$datetime,
                  "temp"=year_out$vals,
                  "seas"=year_out$vals,
                  "thresh"=year_thresh$vals,
                  "thresh_2x"=(year_thresh$vals-year_out$vals)+year_thresh$vals,
                  "thresh_3x"=(((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals,
                  "thresh_4x"=(((((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)

ggplot()+geom_line(data=clim,aes(x=t,y=temp),alpha=0.3)+geom_line(data=clim,aes(x=t,y=thresh),color="goldenrod2")+geom_line(data=clim,aes(x=t,y=seas),color="black")+geom_line(data=clim,aes(x=t,y=thresh_2x),color="orangered")+geom_line(data=clim,aes(x=t,y=thresh_3x),color="firebrick4")+geom_line(data=clim,aes(x=t,y=thresh_4x),color="purple")

out_res<-clim%>%rename("datetime"=t,"vals"=temp)
merged_temp_tri<-vector("list",length(unique(tri_data$reps)))
maxtemptime<-out_res%>%filter(datetime>as.POSIXct('2022-01-01 00:00:00'))%>%filter(vals==max(vals))%>%select(datetime)
maxtemptime<-as.POSIXct(maxtemptime[,1])
reps_list<-unique(tri_data$reps)
clim_2022<-clim%>%filter(t>=as.POSIXct('2022-07-22')&t<as.POSIXct('2022-09-12'))

#fxn to change NA to 0
f_dowle3 = function(DT) {
  for (j in seq_len(ncol(DT)))
    set(DT,which(is.na(DT[[j]])),j,0)
}

#user 2238 system 160 elapsed 3439  - long, but better than an unoptimized left_join at 14000 seconds
#time 2, takes 10684s with an additional 22 simulations
syst<-system.time(
for (i in reps_list){
  #setup
  rep_i<-tri_data%>%dplyr::filter(reps==i) # filter for each MHW
  start_date_rep<-maxtemptime-floor(max(rep_i$duration/2))*60 #find halfway point and subtract from maximum annual timestamp to give start time
  end_date_rep<-start_date_rep+ceiling(max(rep_i$duration))*60
  rep_i$datetime<-seq(from=as.POSIXct(start_date_rep),length.out=ceiling(max(rep_i$timestep)),by="min")

    #much faster method of left_join and na.replace
    system.time(joined_df<-as.data.table(rep_i)[as.data.table(out_res),on='datetime'])
    system.time(f_dowle3(joined_df))


  joined_df$combined_temperature <- joined_df$vals + joined_df$value
  joined_df_short<-joined_df%>%filter(datetime>='2022-07-22 00:00:00'&datetime<'2022-09-12 00:00:00')
  joined_df_short<-joined_df_short%>%rename("time"=datetime,"temp"=combined_temperature)
  
  #now, we categorize each MHW according to the Hobday definition. Note that we have altered code to 1) allow for timeseries in hours (and thus heat wave events classified in hours) and 2) we have removed minimum MHW length (previosuly five days)
repi_selection<-rep_i%>%select(c(value,datetime))%>%rename("t"=datetime)%>%filter(t>='2022-07-22 00:00:00'&t<'2022-09-12 00:00:00')

#0.11
 result_df <- clim_2022 %>%
  left_join(repi_selection, by = "t") %>%
  mutate(sum_temp_value = coalesce(temp + value, temp))%>%select(-c(temp,value))%>%rename("temp"=sum_temp_value)


events<-detect_event_hour(result_df,date_start='2022-07-22',date_end='2022-09-12')
event_categories<-heatwaveR::category(events,S=F,name="simulation")

#because the thresholds are not smoothed function, we occasionally get 
if (nrow(event_categories)>1){
  event_categories<-event_categories%>%slice(which.max(duration))
}

joined_df_short$reps<-reps_list[i]
joined_df_short$duration_hob<-event_categories$duration
joined_df_short$peak_date<-event_categories$peak_date
joined_df_short$category<-event_categories$category
joined_df_short$imax_hob<-event_categories$i_max
joined_df_short$p_moderate<-event_categories$p_moderate
joined_df_short$p_strong<-event_categories$p_strong
joined_df_short$p_severe<-event_categories$p_severe
joined_df_short$p_extreme<-event_categories$p_extreme

ggplot(joined_df_short,aes(x=time,y=temp))+geom_line()


 merged_temp_tri[[i]]<-joined_df_short
 rm(joined_df_short)
}
)

merged_temp_tri<-purrr::compact(merged_temp_tri)

merged_temp_tri_alphas[[xx]]<-merged_temp_tri
}
)

saveRDS(merged_temp_tri_alphas,"data/merged_temp_tri_alphas.RDs")
```

```{r,echo=F}
merged_temp_tri_alphas<-readRDS("data/merged_temp_tri_alphas.RDs") #reading this file in can take a while



#check data
scendf_tri<-merged_temp_tri_alphas[[1]][c(511:521)]
scendf_tri<-bind_rows(scendf_tri)
scendf_tri%>%
  ggplot(aes(x=time,y=temp))+geom_line()+facet_wrap(reps~.)
```

# Two Hypothetical Species

Next, we want to simulate TDT curves for two hypothetical species. We can do this by getting two CTmax and two z parameters, and making TDT curves from those parameters. We will demonstrate here a chronic vs. acute tradeoff.

```{r,echo=F}
set.seed(123)

#set ctmax and z parameters
example_TDT<-data.frame("species"=c("lowct_lowz","highct_highz"),"z"=c(4.5,5.25),"ctmax"=c(45,46))


temp<-rep(seq(26,46,by=2))

# Create an empty data frame to store the results
sim_pred <- vector("list",length=2)
error<-10^(-1)

# Loop over the species
for(m in 1:nrow(example_TDT)){
  # Model of TDT curve
  time <- 10^((example_TDT$ctmax[m] - temp) / example_TDT$z[m])
  
  fit <- lm(log10(time) ~ temp)

  

  sim_results <- data.frame(species = rep(example_TDT$species[m], length(time)),
                                temp = temp,
                                time = time,
                            geom = "line")
    simulated_data <- data.frame()

    for (j in seq_along(temp)) {
       # Generate 10 replicates for each temperature with normal distribution
       replicates <- data.frame(
         temp = rep(temp[j], times = 10),
         time = 10^(rnorm(10, mean(predict(fit, newdata = data.frame(temp = temp[j]))), sqrt(error)))
       )
         # Add to the simulated_data
       replicates$species <- rep(example_TDT$species[m], nrow(replicates))
       replicates$geom="point"
      simulated_data <- bind_rows(simulated_data, replicates)

    }
  
  sim_pred[[m]] <- rbind(simulated_data, sim_results)
}

sim_pred_bound<-bind_rows(sim_pred)

simulated_line<-sim_pred_bound%>%filter(geom=="line")
simulated_point<-sim_pred_bound%>%filter(geom=="point")

temp.df<-simulated_point%>%select(-"geom")


    #we want both examples to have almost no mortality at no MHW
unique_simsp<-unique(sim_pred_bound$species)


models <- by(simulated_point, simulated_point$species, function(sub_df) lm(log10(time) ~ temp, data = sub_df))

int_x <- (models$lowct_lowz$coefficients[1]-models$highct_highz$coefficients[1])/
  (models$highct_highz$coefficients[2]-models$lowct_lowz$coefficients[2])      
    int_y <- models$highct_highz$coefficients[2]*int_x + models$highct_highz$coefficients[1]           



ggplot()+geom_line(data=simulated_line,aes(x=temp,y=time,color=species))+scale_y_log10()+
  geom_point(data=simulated_point,aes(x=temp,y=time,color=species))+theme_classic()+
  ylab("Time to death (minutes)")+xlab("Assay Temperature (°C)")+
  scale_color_discrete(name="Species Strategy",labels=c(expression(paste("Acute Tolerator (High ",CT[max],", High ",italic(z),")")),expression(paste("Chronic Tolerator (Low ",CT[max],", Low ",italic(z),")"))))+
  geom_point(aes(x=int_x,y=10^int_y))+
  geom_segment(aes(x=25,xend=int_x,y=10^int_y,yend=10^int_y),color="black",linetype="dashed",inherit.aes=F)+
  geom_segment(aes(x=int_x,xend=int_x,y=0,yend=10^int_y),color="black",linetype="dashed",inherit.aes=F)+
  annotate("text",x=30,y=5,label="16.9 minutes, 39.53 °C ",size=4)


ggsave(path = "result_figs/supp",filename="twospecies_TDT.tif", device='tiff', dpi=300,width=6,height=4,units="in")


```

# Both species

Now, we can run the simulated TDT curve with the environmental data to get an estimate of mortality for both species

```{r,echo=F,warning=F,eval=F}
####TIME CONSUMING####


#For both hypothetical species, we are only going to look at time series with alpha 0.75
merged_temp_tri<-merged_temp_tri_alphas[[2]]

rm(merged_temp_tri_alphas)
#   user  system elapsed 
#  71.71   60.69 16739  


unique_simsp<-unique(temp.df$species)
final_surv_crosssim_species<-vector("list",length(unique_simsp))
r<-vector("list",length(merged_temp_tri))

numCores <- detectCores()
cl <- makeCluster(numCores-6)
registerDoParallel(cl)

sys.tm <- system.time({
  for (yy in 1:length(unique_simsp)) {
    temp.df_sp <- temp.df %>% dplyr::filter(species == unique_simsp[yy])
    
    results <- foreach::foreach(i = 1:length(merged_temp_tri), .packages = c('tidyverse', 'ggplot2'), .combine = 'rbind') %dopar% {
      tmpi <- rezende_min(merged_temp_tri[[i]], temp.df_sp)
      temp_plat_rep <- purrr::map_dfr(seq_len(2), ~merged_temp_tri[[i]])
      r_subset <- cbind(tmpi, temp_plat_rep)
      
      r_subset <- r_subset %>% dplyr::filter(type == "cum.mort")
      
      final_surv_crosssim_species_n <- data.frame(
        'cum.mort' = min(na.omit(r_subset$mort)),
        "magnitude" = max(r_subset$magnitude),
        "duration" = max(r_subset$duration),
        "rising_slope" = max(r_subset$rising_slope),
        "falling_slope" = max(r_subset$falling_slope),
        "area" = max(r_subset$area),
        "rep" = max(r_subset$rep),
        "mean_i" = max(r_subset$mean_i),
        "hdd" = max(r_subset$hdd),
        "duration_hob" = max(r_subset$duration_hob),
        "peak_date" = max(r_subset$peak_date),
        "category" = max(r_subset$category),
        "imax_hob" = max(r_subset$imax_hob),
        "p_moderate" = max(r_subset$p_moderate),
        "p_strong" = max(r_subset$p_strong),
        "p_severe" = max(r_subset$p_severe),
        "p_extreme" = max(r_subset$p_extreme),
        "species" = unique_simsp[yy],
        "alpha" = 12.75
      )
      
      return(final_surv_crosssim_species_n)
    }
    
    final_surv_crosssim_species[[yy]] <- results
  } # loop for each species
})

parallel::stopCluster(cl)
sys.tm





saveRDS(final_surv_crosssim_species,"data/final_surv_crosssim_species.RDs")
#25772



```

```{r,include=F,warning=F}
#This chunk calculates proportions of mortaltiy factors within categories

final_surv_crosssim_species<-readRDS("data/final_surv_crosssim_species.RDs")
final_surv_crosssim_species_bound<-bind_rows(final_surv_crosssim_species)

#remove MHWs that are less than five days
final_surv_crosssim_species_bound<-final_surv_crosssim_species_bound%>%mutate(category=ifelse(duration<(5*24*60),NA,category))


unique_simsp<-unique(temp.df$species)

cats<-unique(final_surv_crosssim_species_bound$category)
category_prop_list<-vector("list",length=length(cats))
category_list_species<-vector("list",length=length(unique_simsp))


for (j in 1:length(unique_simsp)){
  spi<-final_surv_crosssim_species_bound%>%filter(species==unique_simsp[j])
for (i in 1:length(cats)){
if (is.na(cats[i])) {
    cati <- spi %>% filter(is.na(category))
  } else {cati <- spi %>% filter(category == cats[i])
  }  
  cati$ceilingmort<-(ceiling(cati$cum.mort/5)*5)
  cati$ceilingmort_f<-as.factor(cati$ceilingmort)
  unique_ceiling_mort<-unique(cati$ceilingmort_f)
  cati$leveldens<-1/nrow(cati)
  category_prop_list[[i]]<-cati
}#category
  category_list_species[[j]]<-category_prop_list
}#species
category_prop_species<-bind_rows(category_list_species)



category_prop_species$category <- ifelse(is.na(category_prop_species$category), "No MHW", category_prop_species$category)

category_prop_species$ceilingmort_f<-factor(category_prop_species$ceilingmort_f,levels=c(seq(max(category_prop_species$ceilingmort),min(category_prop_species$ceilingmort),by=-5))) 

category_prop_species$category<-factor(category_prop_species$category,levels=c("No MHW","I Moderate","II Strong", "III Severe","IV Extreme")) 

```

```{r,echo=F,warning=F}



category_prop_species$hours_dur<-category_prop_species$duration/60

category_prop_species$label<-ifelse(category_prop_species$species=="highct_highz","Acute Tolerator","Chronic Tolerator")


species_heatmap_plot<-ggplot(category_prop_species,aes(x=hours_dur,y=magnitude,z=cum.mort,group=species))+geom_tile(aes(fill=cum.mort,color=category),size=0.5)+scale_fill_viridis_c()+theme_classic()+geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  #scale_color_brewer(palette="YlOrRd")+
  scale_color_manual(values=c("cornsilk3","goldenrod2","orangered","firebrick4","purple"))+
  labs(color="MHW Category", fill="Survival (%)")+
  geom_segment(x=5*24,xend=5*24,y=.75,yend=8.25,color="blue",linetype="dashed",linewidth=.75)+
  xlab("Duration (hours)")+facet_wrap(.~label)+
  geom_segment(x=5*24,xend=721,y=.75,yend=.75,color="blue",linetype="dashed",linewidth=.75)+
  ylab("Magnitude (°C)")

species_heatmap_plot
#ggsave(path = "result_figs",filename="species_heatmap.tif", device='tiff', dpi=300,width=8,height=4,units="in")

#without categories
plotnocat<-ggplot(category_prop_species,aes(x=hours_dur,y=magnitude,z=cum.mort,group=label))+geom_tile(aes(fill=cum.mort),linewidth=0.5)+scale_fill_viridis_c()+theme_classic()+geom_contour(color="black")+ geom_text_contour(aes(z = cum.mort),color="black",fontface="bold")+
  #scale_color_brewer(palette="YlOrRd")+
    scale_color_manual(values=c("cornsilk3","goldenrod2","orangered","firebrick4","purple"))+
  labs(color="MHW Category", fill="Survival (%)")+xlab("Duration (hours)")+ 
  facet_wrap(.~label)
  


species.legend<-get_legend(species_heatmap_plot)


```

Now, let's see how altering the thermal adaptation strategy changes sensitivity to different oceanographic definitions of MHWs

```{r,echo=F,warning=F}

# Assuming 'category_prop_species' is your data frame
species_list <- unique(category_prop_species$label)

# Create a table for each species
for (i in 1:length(species_list)) {
  cat(paste("Table for", species_list[i], ":\n"))
  cat("------------------------------\n")
  
  # Subset the data for the current species
  subset_data <- subset(category_prop_species, label == species_list[i])
  
  # Create a table for the current species
  result_table <- table(subset_data$category, subset_data$ceilingmort_f)
  
  # Print the table
  print(result_table)
  
  cat("\n\n")
}

#where does minimum outside MHW mortality occur
(category_prop_species%>%filter(duration<5*24*60))%>%slice_min(cum.mort)

result <- category_prop_species %>%
group_by(ceilingmort_f,category, label) %>%
summarise(total_leveldens = sum(leveldens, na.rm = TRUE))

species_barplot<-result%>%ggplot()+geom_bar(aes(y=total_leveldens,x=category,fill=ceilingmort_f),position='stack',stat='identity')+
  scale_fill_viridis_d(direction=-1)+labs(x="MHW Category",y="Survival Isocline Proportion")+theme_classic()+facet_wrap(.~label)+theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


#ggsave(path = "result_figs",filename="species_barchart.tif", device='tiff', dpi=300,width=8,height=4,units="in")

species_arranged_plot<-plot_grid(species_heatmap_plot+theme(legend.position="none"),
                                 species_barplot+theme(legend.position="none"),
                                 ncol=1,nrow=2,rel_heights=1,labels="AUTO",align="v")

species_arranged_plot_legend<-plot_grid(species_arranged_plot,species.legend,ncol=2,rel_widths=c(1,0.2))
ggdraw(species_arranged_plot_legend+theme(plot.background = element_rect(fill = "white", color = NA)
))
species_arranged_plot_legend

ggsave(path = "result_figs",filename="species_combinedplots.tif", device='tiff', dpi=300,width=8,height=8,units="in")

```

# All Alphas (Annual variability)

Now, we can look at one 'species' and how changing variation changes MHW categories. We will classify MHWs using the three different 90th percentile thresholds we calcualted earlier, at 0.25, 0.75, and 1.5 oC above climatology.

```{r,eval=F,echo=F}
####TIME CONSUMING####


alpha_length<-length(merged_temp_tri_alphas)
alpha_list_short<-c(12.25,12.75,13.5)
surv_crosssim_alphas<-data.frame(
        'cum.mort' =rep(NA,times=527),
        "magnitude" = rep(NA,times=527),
        "duration" = rep(NA,times=527),
        "rising_slope" = rep(NA,times=527),
        "falling_slope" = rep(NA,times=527),
        "area" = rep(NA,times=527),
        "rep" = rep(NA,times=527),
        "mean_i" = rep(NA,times=527),
        "hdd" = rep(NA,times=527),
        "duration_hob" = rep(NA,times=527),
        "peak_date" = rep(NA,times=527),
        "category" = rep(NA,times=527),
        "imax_hob" = rep(NA,times=527),
        "p_moderate" = rep(NA,times=527),
        "p_strong" = rep(NA,times=527),
        "p_severe" = rep(NA,times=527),
        "p_extreme" = rep(NA,times=527),
        "species" = rep(NA,times=527),
        "alpha" = rep(NA,times=527))

for (zz in 1:(alpha_length)){

subset_alpha<-merged_temp_tri_alphas[[zz]]
for (i in 1:length(subset_alpha)){
  r_subset<-subset_alpha[[i]]
final_surv_crosssim_species_alphas_n <- data.frame(
        'cum.mort' =final_surv_crosssim_species[[2]][i,1],
        "magnitude" = max(r_subset$magnitude),
        "duration" = max(r_subset$duration),
        "rising_slope" = max(r_subset$rising_slope),
        "falling_slope" = max(r_subset$falling_slope),
        "area" = max(r_subset$area),
        "rep" = max(r_subset$rep),
        "mean_i" = max(r_subset$mean_i),
        "hdd" = max(r_subset$hdd),
        "duration_hob" = max(r_subset$duration_hob),
        "peak_date" = max(r_subset$peak_date),
        "category" = max(r_subset$category),
        "imax_hob" = max(r_subset$imax_hob),
        "p_moderate" = max(r_subset$p_moderate),
        "p_strong" = max(r_subset$p_strong),
        "p_severe" = max(r_subset$p_severe),
        "p_extreme" = max(r_subset$p_extreme),
        "species" = "highct_highz",
        "alpha" = alpha_list_short[zz])
surv_crosssim_alphas[i,]<-final_surv_crosssim_species_alphas_n


}
final_surv_crosssim_alphas[[zz]]<-surv_crosssim_alphas

}



saveRDS(final_surv_crosssim_alphas,"data/final_surv_crosssim_alphas.RDs")
```

```{r,include=F}

#Assign survival to bins, and assign to categories
final_surv_crosssim_alphas<-readRDS("data/final_surv_crosssim_alphas.RDs")
final_surv_crosssim_alphas_bound<-bind_rows(final_surv_crosssim_alphas)

#remove MHWs that are less than five days
final_surv_crosssim_alphas_bound<-final_surv_crosssim_alphas_bound%>%mutate(category=ifelse(duration<(5*24*60),NA,category))

cats<-unique(final_surv_crosssim_alphas_bound$category)
unique_alphas<-c(12.25,12.75,13.5)

category_prop_list<-vector("list",length=length(cats))
category_prop_list_a<-vector("list",length=length(unique_alphas))

for (j in 1:length(unique_alphas)){
  spi<-final_surv_crosssim_alphas_bound%>%filter(alpha==unique_alphas[j])
for (i in 1:length(cats)){
if (is.na(cats[i])) {
    cati <- spi %>% filter(is.na(category))
  }else{cati <- spi %>% filter(category == cats[i])
  }

  if(nrow(cati)>0){
  cati$ceilingmort<-(ceiling(cati$cum.mort/5)*5)
  cati$ceilingmort_f<-as.factor(cati$ceilingmort)
  unique_ceiling_mort<-unique(cati$ceilingmort_f)
  cati$leveldens<-1/nrow(cati)

  category_prop_list[[i]]<-cati
  }
}
  category_prop_list_a[[j]]<-category_prop_list
}

category_prop_alphas<-bind_rows(category_prop_list_a)


category_prop_alphas$category <- ifelse(is.na(category_prop_alphas$category), "No MHW",category_prop_alphas$category)

category_prop_alphas$category<-factor(category_prop_alphas$category,levels=c("No MHW","I Moderate","II Strong", "III Severe","IV Extreme")) 

category_prop_alphas$ceilingmort_f<-factor(category_prop_alphas$ceilingmort_f,levels=c(seq(max(category_prop_alphas$ceilingmort),min(category_prop_alphas$ceilingmort),by=-5))) 



```

```{r,echo=F}

category_prop_alphas$hour_dur<-category_prop_alphas$duration/60
category_prop_alphas$species<-"High CT, Low z"

# Create a new column 'label'
category_prop_alphas <- category_prop_alphas %>%
  mutate(label = case_when(
    alpha == 12.25 ~ "+ 0.25°C",
    alpha == 12.75 ~ "+ 0.75°C",
    alpha == 13.5 ~ "+ 1.5°C"
  ))

category_prop_alphas <- category_prop_alphas %>%
  mutate(nomhw = case_when(
    alpha == 12.25 ~ 0.25,
    alpha == 12.75 ~ 0.75,
    alpha == 13.5 ~ 1.25
  ))

facet_hlines <- category_prop_alphas %>%
  distinct(nomhw, label)

annual_var_heatmap<-ggplot(category_prop_alphas,aes(x=hour_dur,y=magnitude,z=cum.mort,group=label))+geom_tile(aes(fill=cum.mort,color=category),size=0.5)+scale_fill_viridis_c()+theme_classic()+geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  #scale_color_brewer(palette="YlOrRd")+
    scale_color_manual(values=c("cornsilk3","goldenrod2","orangered","firebrick4","purple"))+
  labs(color="MHW Category", fill="Survival (%)")+
  geom_segment(data = facet_hlines, aes(y = nomhw,yend=8.25,x=5*24,xend=5*24), color = "blue", linetype = "dashed", linewidth = .75,inherit.aes=F)+
  xlab("Duration (hours)")+
  ylab("Magnitude (°C)")+  facet_grid(. ~ label, scales = "free_x", space = "free_x") +  
  geom_segment(data = facet_hlines, aes(y = nomhw,yend=nomhw,x=5*24,xend=721), color = "blue", linetype = "dashed", linewidth = .75,inherit.aes=F)
  #ggtitle("Annual Variation")

annual_var_heatmap

alphas.legend<-get_legend(annual_var_heatmap)

#ggsave(path = "result_figs",filename="alpha_heatmap.tif", device='tiff', dpi=300,width=12,height=4,units="in")
```

Now, let's see how altering seasonal variability changes sensitivity to different oceanographic definitions of MHWs

```{r,echo=F,earning=F}

alphas_list <- unique(category_prop_alphas$label)

# Create a table for each species
for (i in 1:length(alphas_list)) {
  cat(paste("Table for", alphas_list[i], ":\n"))
  cat("------------------------------\n")
  
  # Subset the data for the current species
  subset_data <- subset(category_prop_alphas, label == alphas_list[i])
  
  # Create a table for the current species
  result_table <- table(subset_data$category, subset_data$ceilingmort_f)
  
  # Print the table
  print(result_table)
  
  cat("\n\n")
}

result <- category_prop_alphas %>%
group_by(ceilingmort_f,category, label) %>%
summarise(total_leveldens = sum(leveldens, na.rm = TRUE))

annual_var_barplot<-result%>%ggplot()+geom_bar(aes(y=total_leveldens,x=category,fill=ceilingmort_f),position='stack',stat='identity')+
  scale_fill_viridis_d(direction=-1)+labs(x="MHW Category",y="Survival Isocline Proportion",fill="Survival Isoclines")+theme_classic()+facet_wrap(.~label)+
  #ggtitle("Annual Variation")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

annual_var_barplot

#ggsave(path = "result_figs",filename="alpha_barchart.tif", device='tiff', dpi=300,width=12,height=4,units="in")


annual_arranged_plot<-plot_grid(annual_var_heatmap+theme(legend.position="none"),
                                 annual_var_barplot+theme(legend.position="none"),
                                 ncol=1,nrow=2,rel_heights=1,labels="AUTO",align="v")

alphas_arranged_plot_legend<-plot_grid(annual_arranged_plot,alphas.legend,ncol=2,rel_widths=c(1,0.2))
ggdraw(alphas_arranged_plot_legend+theme(plot.background = element_rect(fill = "white", color = NA)))


ggsave(path = "result_figs",filename="annual_var_combined.tif", device='tiff', dpi=300,width=12,height=8,units="in")

```

# Seasonality

Now, let's simulate the effect of seasonal occurrence on mortality arising from MHWs.We only look at a single duration (24 days) but the same 17 magnitudes from 0 to 8.

```{r,echo=F,warning=F}

magnitude_min<-0.01 #0.01 degree minimum magnitude. Does not accept 0 value
magnitude_max<-8.01 #8 degree duration max.
duration_min<-24*30*60+60*1 #24 days
duration_max<-24*30*60+60*1 # 24 days

magnitude_inc<-0.5 # magnitudes given in 0.5 degree increments 
duration_inc<-0 #durations given in 0 increment - single duration

season_days<-seq(0,90,by=10)

```

```{r,echo=F,awrning=F,eval=F}
####TIME CONSUMING####

#Make the MHWs

MHW_tri_seasons<-function(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc){
  
  #sequence of magnitudes
  mag_seq<-seq(magnitude_min,magnitude_max,by = magnitude_inc)
  #sequence of duration (in minutes)
  #this is if we want a standard time sequence
  dur_seq<-seq(duration_min,duration_max,by = duration_inc)
  
  #create an expanded dataframe of all possible parameter combinations. 
  expanded<-data.frame(expand.grid('mag_seq'=mag_seq,'dur_seq'=dur_seq))
  
  #create empty matrix to store results
  mag_dur_tri <- vector("list", length(mag_seq))
  
  #single loop to create triangles for each row in the expanded dataframe, encapsulating all possible parameters  
  for (i in 1:nrow(expanded)){
    magnitude<-as.numeric(expanded[i,1])
    hw_length<-expanded[i,2] #duration
    #rising_slope<-expanded[i,3] if we vary slope
    rising_slope<-magnitude/(hw_length/2)
    #create df of dates and numerical sequence
    
    rising_length<-magnitude/rising_slope
    falling_length<-hw_length-rising_length
    if (is.na(rising_length) || is.na(hw_length)) {
      print("Debug: Missing value in rising_length or hw_length")
      #add ifelse to remove unlikely initial slope values
    } else if(rising_length>=hw_length){#if rising portion is longer than entire mhw duration
      z<-data.frame("timestep"=NA,"value"=NA,"magnitude"=magnitude,"duration"=hw_length,"rising_slope"=rising_slope,"falling_slope"=NA,"area"=NA,"mean_i"=NA,"hdd"=NA)

    } else {
      falling_slope<-(-rising_slope)
      #dataframes of rising falling points
      rising_seq<-data.frame("timestep"=seq(1,floor(max(rising_length)),by=1))
      falling_seq<-data.frame("timestep"=seq(from=floor(max(rising_length))+1,to=hw_length,by = 1))
      
      rising_seq$value<-rising_seq$timestep*rising_slope
      falling_seq$value<-(falling_seq$timestep*falling_slope)+(max(rising_length)*magnitude/nrow(falling_seq))+magnitude
      
      #apply values
      
      z<-rbind(rising_seq,falling_seq)
      z$reps<-i
      z$magnitude<-magnitude
      z$duration<-hw_length
      z$rising_slope<-rising_slope
      z$falling_slope<-falling_slope
      z$area<- magnitude*hw_length/2
      z$mean_i<-mean(z$value)
      #heating degree days
      #first, create a column of day 
      if(hw_length<1440){
        z$unique_day<-hw_length
      }else{
        z$unique_day<-(z$timestep-1)%/%1440+1
      }
      
      hdd_tib<-z%>%group_by(unique_day)%>%summarize(mean_t=mean(value))%>%summarize(output=sum(mean_t))
      z$hdd<-hdd_tib$output
    }
    
    
    mag_dur_tri[[i]] <- z
  }
  
  boundoutput_tri<-bind_rows(mag_dur_tri,.id="reps") #from matrix to data.frame
  boundoutput_tri$reps<-as.numeric(boundoutput_tri$reps)

  return(ggplot(data=boundoutput_tri,aes(x=timestep,y=value,group=reps,color=reps))+geom_line()+ theme(legend.position="none")+scale_color_viridis_c())
  
}


system.time(seasonal_tris<-MHW_tri_seasons(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc,slope_inc))

tri_data<-seasonal_tris$data
```

```{r,earning=F,echo=F,eval=T}

#Make the Climatology

year_out<-waves('2022-01-01 00:01:00','2022-12-31 00:00:00',alpha=12,beta=14,freq=365*24)

year_thresh<-waves('2022-01-01 00:01:00','2022-12-31 00:00:00',alpha=12.75,beta=14,freq=365*24)


clim<-data.frame("hoy"=lubridate::hour(year_out$datetime) + (lubridate::yday(year_out$datetime) - 1) * 24,
                 "doy"=lubridate::yday(year_out$datetime),
                 "t"=year_out$datetime,
                 "temp"=year_out$vals,
                 "seas"=year_out$vals,
                 "thresh"=year_thresh$vals,
                 "thresh_2x"=(year_thresh$vals-year_out$vals)+year_thresh$vals,
                 "thresh_3x"=(((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals,
                 "thresh_4x"=(((((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)

clim<-clim%>%filter(t>as.POSIXct('2022-07-01 01:00:00'))
out_res<-clim%>%rename("datetime"=t,"vals"=temp)
mintemptime<-out_res%>%filter(datetime>as.POSIXct('2022-07-01 00:00:00'))%>%filter(vals==min(vals))%>%select(datetime)
mintemptime<-as.POSIXct(mintemptime[,1])
reps_list<-unique(tri_data$reps)


```

```{r,echo=F,awrning=F,eval=F}
####TIME CONSUMING####

#join them together

start_day<-as.POSIXct(clim %>% slice_max(temp)%>%pull(t))-lubridate::days(16)
end_day<-as.POSIXct(clim %>% slice_max(temp)%>%pull(t))+lubridate::days(16)

season_days<-seq(0,90,by=10)

merged_temp_tri_seasons<-vector("list",length=length(season_days))
merged_temp_tri_season<-vector("list",length(unique(tri_data$reps)))


f_dowle3 = function(DT) {
  for (j in seq_len(ncol(DT)))
    set(DT,which(is.na(DT[[j]])),j,0)
}



system.time(for (k in 1:length(season_days)){
  #fxn to change NA to 0
  start_date_rep<-start_day+lubridate::days(season_days[k])
  end_date_rep<-end_day+lubridate::days(season_days[k])
  
  mid_date_rep<-start_date_rep+lubridate::days(floor(end_date_rep-start_date_rep))/2
  
  for (i in reps_list){
    #setup
    rep_i<-tri_data%>%dplyr::filter(reps==i) # filter for each MHW
    
    start_date_rep<-mid_date_rep-floor(max(rep_i$duration/2))*60-lubridate::hours(1) #find halfway point and subtract from maximum annual timestamp to give start time
    end_date_rep<-start_date_rep+ceiling(max(rep_i$duration))*60
    
    rep_i$datetime<-seq(from=as.POSIXct(start_date_rep),length.out=ceiling(max(rep_i$timestep)),by="min")
    
    #much faster method of left_join and na.replace
    system.time(joined_df<-as.data.table(rep_i)[as.data.table(out_res),on='datetime'])
    system.time(f_dowle3(joined_df))
    
    
    joined_df$combined_temperature <- joined_df$vals + joined_df$value
    joined_df_short<-joined_df
    joined_df_short<-joined_df_short%>%rename("t"=datetime,"temp"=combined_temperature)
    

    events<-detect_event_hour(joined_df_short,date_start=season_start_dates[k],date_end=season_end_dates[k])
    event_categories<-heatwaveR::category(events,S=F,name="simulation")
    
    #because the thresholds are not smoothed function, we occasionally get more than one category. Fix if so. 
    if (nrow(event_categories)>1){
      event_categories<-event_categories%>%slice(which.max(duration))
    }
    
    joined_df_short$duration_hob<-event_categories$duration
    joined_df_short$peak_date<-mid_date_rep
    joined_df_short$category<-event_categories$category
    joined_df_short$imax_hob<-event_categories$i_max
    joined_df_short$p_moderate<-event_categories$p_moderate
    joined_df_short$p_strong<-event_categories$p_strong
    joined_df_short$p_severe<-event_categories$p_severe
    joined_df_short$p_extreme<-event_categories$p_extreme
    joined_df_short$days_past_peak<-season_days[k]
    
    merged_temp_tri_season[[i]]<-joined_df_short
  }
  
  merged_temp_tri_season<-purrr::compact(merged_temp_tri_season)
  saveRDS(object = merged_temp_tri_season, file = paste0("data/season_mhw_stacks/mhw_stack",k,".Rds"))
  

}
)


```

```{r,echo=F,warning=F,eval=F}
####TIME CONSUMING####


#Get survival from the paired climatology and MHWs

sp_filtered<-temp.df%>%filter(species=="highct_highz")


season_cont_result_mort<-data.frame(
  'cum.mort' = NA,
  "magnitude" = NA,
  "duration" = NA,
  "rising_slope" = NA,
  "falling_slope" = NA,
  "area" = NA,
  "rep" = NA,
  "mean_i" = NA,
  "hdd" = NA,
  "duration_hob" = NA,
  "peak_date" = NA,
  "category" = NA,
  "imax_hob" = NA,
  "p_moderate" = NA,
  "p_strong" = NA,
  "p_severe" = NA,
  "p_extreme" = NA,
  "species" = NA,
  "alpha" = NA,
  "season"=NA,
  "dayspostpeak")

season_cont_result<-vector("list",length=length(season_days))
season_cont_result_mort<-vector("list",length=17)

for (i in 1:length(season_days)){
mhw_stack<-readRDS(paste0("data/season_mhw_stacks/mhw_stack",i,".RDs"))

for (k in 1:length(mhw_stack)){
stacki<-mhw_stack[[k]][-c(262081:263520),]
stacki$t<-as.POSIXct(stacki$t, format = "%Y-%m-%d %H:%M:%S", origin = "1970-01-01")
# Now, you can use the ggplot code
stacki$time<-stacki$t
tmpi <- rezende_min(stacki, sp_filtered)
temp_stack <- purrr::map_dfr(seq_len(2), ~stacki)
r_subset <- cbind(tmpi, temp_stack)

r_subset <- r_subset %>% dplyr::filter(type == "cum.mort")

final_surv_crosssim_season_n <- data.frame(
  'cum.mort' = min(na.omit(r_subset$mort)),
  "magnitude" = max(r_subset$magnitude),
  "duration" = max(r_subset$duration),
  "rising_slope" = max(r_subset$rising_slope),
  "falling_slope" = max(r_subset$falling_slope),
  "area" = max(r_subset$area),
  "rep" = max(r_subset$rep),
  "mean_i" = max(r_subset$mean_i),
  "hdd" = max(r_subset$hdd),
  "duration_hob" = max(r_subset$duration_hob),
  "peak_date" = as.POSIXct(max(r_subset$peak_date)),
  "category" = unique(r_subset$category),
  "imax_hob" = max(r_subset$imax_hob),
  "p_moderate" = max(r_subset$p_moderate),
  "p_strong" = max(r_subset$p_strong),
  "p_severe" = max(r_subset$p_severe),
  "p_extreme" = max(r_subset$p_extreme),
  "species" = "highct_highz",
  "alpha" = 12.75,
  "season"=as.POSIXct(start_day,origin='1970-01-01 00:00:00')+lubridate::days(season_days[i]),
  "dayspostpeak"=season_days[i])
   
season_cont_result_mort[[k]]<-final_surv_crosssim_season_n

}
season_cont_result_mort2<-bind_rows(season_cont_result_mort)
season_cont_result[[i]]<-season_cont_result_mort
}

season_cont_result<-bind_rows(season_cont_result)

saveRDS(season_cont_result,"data/season_cont_result_mort.RDs")


```

```{r,echo=F,warning=F}

season_cont_result<-readRDS('data/season_cont_result_mort.RDs')

season_cont_result$cum.mort<-season_cont_result$cum.mort/100

season_cont_result$season<-as.POSIXct(season_cont_result$season)

surv_plot<-ggplot(data=season_cont_result,aes(x=season,y=cum.mort,group=magnitude,color=magnitude))+
  geom_line()+
  geom_point()+
  scico::scale_color_scico(palette = "lajolla")+
  theme_classic()+labs(y="Survival Proportion",x="Date of MHW Start",color="Magnitude (°C)")+
  scale_x_datetime(date_breaks="month",date_labels="%b",limits=c(as.POSIXct('2022-08-01'),as.POSIXct('2022-11-30')))

surv_plot
#ggsave(path = "result_figs",filename="seasonal_mhw_placement.tif", device='tiff', dpi=300,width=6,height=4,units="in")


```

```{r,echo=F,warning=F,eval=F}
####TIME CONSUMING####

#Get seasonal occurrence timeseries plot - reduce to hours for computational reasons

#Let's try something different for speed - adjusting each MHW to the timeseries rather than adding them together
maxtemptime <- out_res %>%
  filter(datetime > as.POSIXct('2022-07-01 00:00:00', tz = "UTC")) %>%
  filter(vals == max(vals)) %>%
  select(datetime) %>%
  pull()

reps_list<-unique(tri_data$reps)
clim$t<-as.POSIXct(clim$t,tz="UTC")


singleseason<-vector("list",length=length(reps_list))
allseasons<-vector("list",length=length(season_days))



for (i in 1:length(season_days)){
  add_days<-season_days[i]
  for (j in reps_list){
    #setup
    rep_i<-tri_data%>%dplyr::filter(reps==j) # filter for each MHW
    start_time <- lubridate::force_tz(maxtemptime + lubridate::days(add_days) - (lubridate::minutes(max(rep_i$duration) / 2)),tz="UTC")
    end_time <- lubridate::force_tz(
      maxtemptime + lubridate::days(add_days) + (lubridate::minutes(max(rep_i$duration) / 2))-lubridate::minutes(1)
      ,tz="UTC")
  
    

    rep_i$datetime <- seq(start_time,end_time,by = "min")
      
    
    clim2<-clim%>%rename("datetime"="t","clim_temp"="temp")
    merged_temps<-merge(clim2,rep_i,by=('datetime'))
    merged_temps$merged_temp<-merged_temps$value+merged_temps$clim_temp
    merged_temps$season_day<-as.factor(add_days)
    singleseason[[j]]<-merged_temps
    }
  allseasons[[i]]<-singleseason
}
allseasons_bound<-bind_rows(allseasons)
allseasons_bound_hour<-allseasons_bound %>%
  mutate(hour = format(datetime, "%Y-%m-%d %H:00")) %>%
  group_by(hour) %>%
  filter(datetime == min(datetime))

saveRDS(allseasons_bound_hour,"data/allseasons_bound.RDs")


```

```{r,echo=F,warning=F}

allseasons_bound_hour<-readRDS("data/allseasons_bound.RDs")

maxtemptime <- out_res %>%
  filter(datetime > as.POSIXct('2022-07-01 00:00:00', tz = "UTC")) %>%
  filter(vals == max(vals)) %>%
  select(datetime) %>%
  pull()


alignment_points<-data.frame("datetime"=maxtemptime + lubridate::days(season_days))
alignment_points_df<-left_join(alignment_points,allseasons_bound_hour)

occ_plot<-ggplot(data=allseasons_bound_hour)+
  labs(x="Date",y="Temperature (°C)")+
  theme_classic()+
  geom_line(aes(x=datetime,y=thresh,color="I Moderate"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_2x,color="II Strong"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_3x,color="III Severe"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_4x,color="IV Extreme"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=clim_temp,color="Climatology"),inherit.aes = F)+
  scale_color_manual(values=c("Climatology"="black",
                              "I Moderate"="goldenrod2","II Strong"="orangered","III Severe"="firebrick4",
                              "IV Extreme"='purple',"Simulated MHW"="cornsilk3"))+
  theme(legend.title=element_blank())

mhwcat.legend<-get_legend(occ_plot)

occ_plot2<-ggplot(data=allseasons_bound_hour,aes(x=datetime,y=merged_temp))+
  geom_line(aes(group=interaction(season_day,magnitude),color=magnitude),alpha=0.5,linewidth=1)+
  scico::scale_color_scico(palette = "lajolla")+
  labs(x="Date",y="Temperature (°C)",color="Magnitude (°C)")+
  theme_classic()+
  geom_line(aes(x=datetime,y=thresh),color="goldenrod2",linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_2x),color="orangered",linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_3x),color="firebrick4",linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_4x),color="purple",linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=clim_temp),color="black",inherit.aes = F)+
  geom_point(data=alignment_points_df,aes(x=datetime,y=clim_temp),color="black",fill="white",inherit.aes=F,shape=21)

occ.legend<-get_legend(occ_plot2)
  
occ_plot2

#ggsave(path = "result_figs",filename="timeseries.tif", device='tiff', dpi=300,width=6,height=4,units="in")

occ_arranged_plot<-plot_grid(occ_plot2+theme(legend.position="none"),
                                 surv_plot+theme(legend.position="none"),
                                 ncol=1,nrow=2,rel_heights=1,labels="AUTO",align="v")
legend_occ_combined<-plot_grid(mhwcat.legend,occ.legend,nrow=2)
occ_arranged_plot_legend<-plot_grid(occ_arranged_plot,legend_occ_combined,ncol=2,rel_widths=c(1,0.4),scale=c(1,0.75))
ggdraw(occ_arranged_plot_legend+theme(plot.background = element_rect(fill = "white", color = NA)))

ggsave(path = "result_figs",filename="timeseries_survprop.tif", device='tiff', dpi=300,width=6,height=8,units="in")


```

Below we see how the seasonal occurrence of a MHW impacts cumulative survival at the end of each MHW across magnitudes

```{r,echo=F,warning=F,eval=F}

#categories along season


#remove MHWs that are less than five days
season_cont_result<-season_cont_result%>%mutate(category=ifelse(duration<(5*24*60),NA,category))


unique_season<-unique(season_cont_result$season)

cats<-unique(season_cont_result$category)
category_prop_list<-vector("list",length=length(cats))
category_list_season<-vector("list",length=length(unique_season))


for (j in 1:length(unique_season)){
  seasi<-season_cont_result%>%filter(season==unique_season[j])
  for (i in 1:length(cats)){
    if (is.na(cats[i])) {
      cati <- seasi %>% filter(is.na(category))
    } else {cati <- seasi %>% filter(category == cats[i])
    }  
    cati$ceilingmort<-(round(cati$cum.mort/0.05)*0.05)*100
    cati$ceilingmort_f<-as.factor(cati$ceilingmort)
    unique_ceiling_mort<-unique(cati$ceilingmort_f)
    cati$leveldens<-if(nrow(cati)==0){}else{1/nrow(cati)}
    category_prop_list[[i]]<-cati
  }#category
  category_list_season[[j]]<-category_prop_list
}#species
category_prop_season<-bind_rows(category_list_season)

category_prop_season <- category_prop_season %>%
  mutate(category = ifelse(is.na(category), "No MHW", category))


category_prop_season$category<-factor(category_prop_season$category,
                                      levels=c("No MHW","I Moderate","II Strong", "III Severe","IV Extreme")) 



comparison<-category_prop_season %>%
  group_by(dayspostpeak , category,ceilingmort) %>%
  summarise(count = n()) %>%
  group_by(dayspostpeak ,category) %>%
  mutate(proportion = count / sum(count))



saveRDS(comparison,"data/category_prop_season.RDs")
```

```{r,echo=F,warning=F}
####TIME CONSUMING####

comparison<-readRDS("data/category_prop_season.RDs")



comparison$ceilingmort<-as.factor(comparison$ceilingmort*100)

new_labels <- c("0" = "Summer Peak", "10" = "10 days post peak", "20" = "20 days post peak", "30" = "40 days post peak",
                "40"="40 days post peak","50"="50 days post peak","60"="60 days post peak","70"="70 days post peak",
                "80"="80 days post peak","90"="90 days postpeak")

occ_barplot<-ggplot(data=comparison,aes(x=category,y=proportion,fill=ceilingmort))+
  geom_bar(stat='identity',position = position_fill(reverse = TRUE))+facet_wrap(dayspostpeak ~.,labeller = labeller(dayspostpeak = new_labels))+
  scale_fill_viridis_d()+theme_classic()+
  labs(x="MHW Category",y="Survival Isocline Proportion",fill="Survival Isoclines")+theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))+
  guides(fill = guide_legend(reverse=TRUE))

occ_arranged_plot_legend<-plot_grid(occ_barplot,legend_occ_combined,ncol=2,rel_widths=c(1,0.4),scale=c(1,0.75))
ggdraw(occ_arranged_plot_legend+theme(plot.background = element_rect(fill = "white", color = NA)))

ggsave(path = "result_figs","seasonal_occ_arplot.tif",device="tiff",width=12,height=8,units=c("in"))  

```

# Citations
