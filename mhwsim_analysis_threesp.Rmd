---
title: "Marine Heatwave Simulation Analysis"
author: "Andrew Villeneuve"
date: "2024-04-12"
output: html_document
bibliography: references.bib
---

# Data analysis introduction

The below analysis creates all figures in Villeneuve and White 2024. The document can be knitted to reproduce the entire analysis. All chunks of this markdown can be run as well, but certain chunks are computationally intensive and can take many hours to complete. These time-consuming chunks are labelled. In key places, we have saved .RDs data files of computational outputs at strategic checkpoints to allow for rapid knitting of the document. These .RDs files are included in the repository for convenience, but are not included in github due to size restrictions.

Two exterior R files are called to define functions used in this analysis. They are as follows:

-   hour_fxns_heatwaveR.R - This file contains ad hoc functions drawn from the heatwaveR package [@schlegel2018]. We edited these functions for our own use to allow for input of hourly data.***NOTE: as of April 12th, 2024, heatwaveR now has hourly capability built into all functions. We recommend still running our ad hoc functions, as this code has not been tested with the updated heatwaveR functions. 
-   Thermal_landscape_functions.R - This file contains ad hoc functions drawn from @rezende2020 to calculate static thermal tolerance landscapes and calculate survival over variable temperature time series using a dynamic thermal tolerance model. We edited these functions to incorporate the concept of critical temperature @jørgensen2021 , the temperature at which temperature stress starts to become lethal.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(lubridate)
require(tibble)
require(tidyr)
require(ggplot2)
library(kableExtra)
require(purrr)
require(metR)
require(parallel)
require(foreach)
require(ggforce)
require(data.table)
require(zoo)
require(cowplot)
require(doParallel)
require(rlang)
require(reshape2)
require(heatwaveR)
require(ggside)
require(ggpubr)
require(terra)
require(SpatialTools)


options(scipen=999)

source("Thermal_landscape_functions.R")
source("hour_fxns_heatwaveR.R") #adhoc heatwaveR functions, see note above

#official MHW color scale (Hobday et al. 2018) + cornsilk (this paper)
MHW_colours <- c(
  'No MHW'="cornsilk3",
  "I Moderate" = "#ffc866",
  "II Strong" = "#ff6900",
  "III Severe" = "#9e0000",
  "IV Extreme" = "#2d0000"
)

    #a function to turn NAs in a data table into zeros (useful for binding datatables of different lengths)
f_dowle3 = function(DT) {
  for (j in seq_len(ncol(DT)))
    set(DT,which(is.na(DT[[j]])),j,0)
}
```

# A function for constructing all possible MHWs from a set of parameters

The first step in this project is to create a function that allows for the construction of all possible MHWs from a range of values for each parameter (magnitude, duration, and rate of onset). For rate of onset, we use duration of onset instead of slope itself, as slope is dependent on magnitude of each event.

Below, we set up the range of parameters. All times must be in minutes, all temperatures are in degrees Celsius.

```{r,echo=T}
magnitude_min<-0.01 #0.01 degree minimum magnitude. Analysis does not accept 0 value
magnitude_max<-8.01 #8 degree duration max. This is in agreement with observed values above climatology across multiple major MHW events
duration_min<-60*1 #one hour MHW min  Here, we differ from other definitions (Hobday et al. 2016) that set minimum values of 5 days for a MHW event. For intertidal organisms, a few hours of extreme heat during low tide during an atmospheric heatwave may cause mortality and should be considered from an ecophysiological perspective. 
duration_max<-24*30*60+60*1 # 30 day MHW max - MHWs can commonly last multiple days, weeks, or months. However, for the sake of this initial analysis, we reduce that to three day for speed of calculation.Note that this is technically 30 days plus one hour, to keep intervals between durations the same. 

magnitude_inc<-0.5 # magnitudes given in 0.5 degree increments 
duration_inc<-24*60 #durations given in 24 hour increments (MUST be in minutes)
slope_inc<-NA #possible to manipulate the slope of MHWs to arrive at 'plateau' shape

```

Now, we can set up the function that creates all possible plateau possibilities from this range of parameters. Note that you must change where the R data file (.RDs) are saved - here, I save them in my personal onedrive folder due to space restrictions on github.

Note that the function below allows for manipulating the slope of MHWs with a slope_inc parameter. The rest of the markdown analysis assumes no change in slope, and so we present this portion of the function here for future reference only.

```{r,echo=F,include=F}


MHW_tri<-function(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc,slope_inc){
  
  #sequence of magnitudes
  mag_seq<-seq(magnitude_min,magnitude_max,by = magnitude_inc)
  
  #sequence of duration (in minutes)
  dur_seq<-seq(duration_min,duration_max,by = duration_inc)
  
  if (is.na(slope_inc)){

  #create an expanded dataframe of all possible parameter combinations. 
  
  expanded<-data.frame(expand.grid('mag_seq'=mag_seq,'dur_seq'=dur_seq))
  } else{
  slope_seq<-seq(0.0001,6/360,by=slope_inc)
  expanded<-data.frame(expand.grid('mag_seq'=mag_seq,'dur_seq'=dur_seq,'slope_seq'=slope_seq)) # if we want to control slope
  }
  
    #create empty matrix to store results
  mag_dur_tri <- vector("list", length(mag_seq))
  
  #single loop to create triangles for each row in the expanded dataframe, encapsulating all possible parameters  
  for (i in 1:nrow(expanded)){
    magnitude<-as.numeric(expanded[i,1])
    hw_length<-expanded[i,2] #duration
    #rising_slope<-expanded[i,3] if we vary slope
    rising_slope<-magnitude/(hw_length/2)
    #create df of dates and numerical sequence
    
    rising_length<-magnitude/rising_slope
    falling_length<-hw_length-rising_length
    if (is.na(rising_length) || is.na(hw_length)) {
      print("Debug: Missing value in rising_length or hw_length")
    #add ifelse to remove unlikely initial slope values
    } else if(rising_length>=hw_length){#if rising portion is longer than entire mhw duration
      z<-data.frame("timestep"=NA,"value"=NA,"magnitude"=magnitude,"duration"=hw_length,"rising_slope"=rising_slope,"falling_slope"=NA,"area"=NA,"mean_i"=NA,"hdd"=NA)
    } else {
    falling_slope<-(-rising_slope)
    #dataframes of rising falling points
    rising_seq<-data.frame("timestep"=seq(1,floor(max(rising_length)),by=1))
    falling_seq<-data.frame("timestep"=seq(from=floor(max(rising_length))+1,to=hw_length,by = 1))
    
    rising_seq$value<-rising_seq$timestep*rising_slope
    falling_seq$value<-(falling_seq$timestep*falling_slope)+(max(rising_length)*magnitude/nrow(falling_seq))+magnitude
    
    #apply values

    z<-rbind(rising_seq,falling_seq)
    z$reps<-i
    z$magnitude<-magnitude
    z$duration<-hw_length
    z$rising_slope<-rising_slope
    z$falling_slope<-falling_slope
    z$area<- magnitude*hw_length/2
    z$mean_i<-mean(z$value)
    #heating degree days
    #first, create a column of day 
    if(hw_length<1440){
      z$unique_day<-hw_length
    }else{
    z$unique_day<-(z$timestep-1)%/%1440+1
    }
  
    hdd_tib<-z%>%group_by(unique_day)%>%summarize(mean_t=mean(value))%>%summarize(output=sum(mean_t))
    z$hdd<-hdd_tib$output
    }

    
    mag_dur_tri[[i]] <- z
    }
  
  boundoutput_tri<-bind_rows(mag_dur_tri,.id="reps") #from matrix to data.frame
  boundoutput_tri$reps<-as.numeric(boundoutput_tri$reps)
  saveRDS(boundoutput_tri,"data/boundoutput_tri.RDs") #saves file to onedrive due to space restrictions in github. Can be silenced. 
  
  return(ggplot(data=boundoutput_tri,aes(x=timestep,y=value,group=reps,color=reps))+geom_line()+ theme(legend.position="none")+scale_color_viridis_c())
  
  }



```

Here, we can see the resulting triangles from our range of parameters.

```{r,echo=F,eval=F}
####TIME CONSUMING####
system.time(MHW_tri(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc,slope_inc))

#tri_output
```

```{r,echo=F,warning=F}
#read in stored data of MHW triangles
tri_outputme<-readRDS('data/boundoutput_tri.RDs')

  
tri_data<-tri_outputme #rename
tri_data$duration<-tri_data$duration/60 #convert to hours for plotting

tri_data$label<-paste(tri_data$magnitude, "°C", sep = "")

#for visualization sake, we select 0,2,4,6,and 8 magnitudes and 0, 5, 10, 15, 20, 25, and 30 days
tri_data.select<-tri_data%>%filter(magnitude==c(0.01,2.01,4.01,6.01,8.01)&duration==c(1,121,241,361,481,601,721))

ggplot(data=tri_data.select,aes(x=timestep/60,y=value,group=reps,color=magnitude))+geom_line()+ theme(legend.position="none")+scale_color_viridis_c(option="plasma")+theme_classic()+ylab("Magnitude (°C)")+xlab("Duration (h)")+labs(color="Duration (h)")

```

# Simulating annual time series

Now that we have simulated MHW triangles, we need to add these on top of a typical temperature time series for a given location. First, let's simulate one year of data using a sine wave, then add oceanographic, fixed baseline categories of MHWs [@schlegel2018, @hobday2018].

```{r,echo=F,warning=F,include=F}
## function for creating sine wave
##function from user beckmw https://www.r-bloggers.com/2017/04/predicting-tides-in-r/
waves <- function(date_start,date_end, alpha = 0, beta = 1, freq = 24, phi = 0){
  
  start <- as.POSIXct(date_start)
  end<-as.POSIXct(date_end)
  x <- seq(start, end, by = 60 * 1)
  
  
  # timestep per hour
  time_step <- 60 / unique(diff(x))
  # set phi as difference in hours from start of time_in
  phi <- min(x) + phi * 3600
  phi<- as.numeric(difftime(phi, min(x)))
  phi <- phi / time_step
  # get input values to cos func
  in_vals <- seq(0, length(x), length = length(x))
  in_vals <- in_vals / time_step
  in_vals <- 2 * pi * in_vals * 1 / freq
  # wave
  y <- alpha + beta * sin((in_vals + phi)-(pi*.75))
  df<-data.frame("vals"=y,"datetime"=x)
  return(df)
}
```

```{r,include=F,eval=F}
####TIME CONSUMING####

year_out<-waves('2022-01-01','2022-12-31',alpha=12,beta=14,freq=365*24)#choice of 2022 is arbitrary

#list of interannual variability parameters
alpha_list<-c(12.25,12.75,13.5)

merged_temp_tri_alphas<-vector("list",length=length(alpha_list))


system.time(
  for (xx in 1:length(alpha_list)){
    year_thresh<-waves('2022-01-01','2022-12-31',alpha=alpha_list[xx],beta=14,freq=365*24)
    
    
    clim<-data.frame("hoy"=lubridate::hour(year_out$datetime) + (lubridate::yday(year_out$datetime) - 1) * 24,
                     "doy"=lubridate::yday(year_out$datetime),
                     "t"=year_out$datetime,
                     "temp"=year_out$vals,#climatology
                     "seas"=year_out$vals,#seasonal. Here, is the same as climatology. 
                     "thresh"=year_thresh$vals, #thresh one of alpha_list values
                     "thresh_2x"=(year_thresh$vals-year_out$vals)+year_thresh$vals,
                     "thresh_3x"=(((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals,
                     "thresh_4x"=(((((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)
    
    
    clim_2022<-clim%>%dplyr::filter(t>=as.POSIXct('2022-07-22')&t<as.POSIXct('2022-09-12'))#filter to a usable range
    out_res<-clim_2022%>%dplyr::rename("datetime"=t,"vals"=temp)
    
    merged_temp_tri<-vector("list",length(unique(tri_data$reps)))
    
    maxtemptime<-out_res%>%dplyr::filter(datetime>as.POSIXct('2022-01-01 00:00:00'))%>%
      dplyr::filter(vals==max(vals))%>%dplyr::select(datetime) #extracts datetime of highest annual temperature
    
    maxtemptime<-as.POSIXct(maxtemptime[,1])
    reps_list<-unique(tri_data$reps)
    length(reps_list)
    
    #user 2238 system 160 elapsed 3439 on 16gb ram i7 8th gen intel

    syst<-system.time(
      for (i in 1:length(reps_list)){
        #setup
        rep_i<-tri_data%>%dplyr::filter(reps==i) # filter for each MHW
        start_date_rep<-maxtemptime-floor(max(rep_i$duration/2))*60 #find halfway point and subtract from maximum annual timestamp to give start time
        end_date_rep<-start_date_rep+ceiling(max(rep_i$duration))*60 # ditto, for end time
        rep_i$datetime<-seq(from=as.POSIXct(start_date_rep),length.out=ceiling(max(rep_i$timestep)),by="min")
        
        #much faster method of left_join and na.replace
        joined_df<-as.data.table(rep_i)[as.data.table(out_res),on='datetime']
         system.time(f_dowle3(joined_df))
        joined_df<-as.data.frame(joined_df)#just making sure! 
        joined_df$value<-ifelse(is.na(joined_df$value),0,joined_df$value)#NAs become 0
        joined_df$combined_temperature <- joined_df$vals + joined_df$value # value is from MHW triangles, vals are sine waves
        joined_df_short<-joined_df%>%dplyr::filter(datetime>=as.POSIXct('2022-07-22 00:00:00')&datetime<as.POSIXct('2022-09-12 00:00:00'))#again, filtering to manageable size
        joined_df_short<-joined_df_short%>%rename("time"=datetime,"temp"=combined_temperature)
        
        #now, we categorize each MHW according to the Hobday definition. Note that we have altered code to 1) allow for timeseries in hours (and thus heat wave events classified in hours) and 2) we have removed minimum MHW length (previosuly five days).
        
        
        repi_selection<-rep_i%>%dplyr::select(c(value,datetime))%>%dplyr::rename("t"=datetime)%>%dplyr::filter(t>='2022-07-22 00:00:00'&t<'2022-09-12 00:00:00')
        
        result_df <- clim_2022 %>%
          left_join(repi_selection, by = "t") %>%
          mutate(sum_temp_value = coalesce(temp + value, temp))%>%dplyr::select(-c(temp,value))%>%dplyr::rename("temp"=sum_temp_value)
        
        
        events<-detect_event_hour(result_df,date_start='2022-07-22 00:00:00',date_end='2022-09-12 00:00:00')
        event_categories<-heatwaveR::category(events,S=F,name="simulation")
        
        #if more than one category recorded, choose the biggest one (very rare, may be artifact from older analysis) 
        if (nrow(event_categories)>1){
          event_categories<-event_categories%>%dplyr::slice(which.max(duration))
        }
        
        joined_df_short$reps<-reps_list[i]
        joined_df_short$duration_hob<-event_categories$duration
        joined_df_short$peak_date<-event_categories$peak_date
        joined_df_short$category<-event_categories$category
        joined_df_short$imax_hob<-event_categories$i_max
        joined_df_short$p_moderate<-event_categories$p_moderate
        joined_df_short$p_strong<-event_categories$p_strong
        joined_df_short$p_severe<-event_categories$p_severe
        joined_df_short$p_extreme<-event_categories$p_extreme
        

        
        merged_temp_tri[[i]]<-joined_df_short
        rm(joined_df_short)
        
              }
      
    )
    #saveRDS(merged_temp_tri,paste0("data/merged_temp_tri_",xx,".RDs")) #big files, unsilence if you want to run this chunk yourself.
    merged_temp_tri<-purrr::compact(merged_temp_tri)
    
    merged_temp_tri_alphas[[xx]]<-merged_temp_tri
  }
)


#saveRDS(merged_temp_tri_alphas,"data/merged_temp_tri_alphas.RDs") #also a big file, unsilence if re-rendering this chunk. 
```

```{r,echo=F,eval=F}
#merged_temp_tri_alphas<-readRDS("data/merged_temp_tri_alphas.RDs") #reading this file in can take a while. Not hosted on github, 5GB. If you want this file, email Drew at drew.villeneuve@unh.edu

#check data
scendf_tri<-merged_temp_tri_alphas[[1]][c(511:521)]
scendf_tri<-bind_rows(scendf_tri)
scendf_tri%>%
  ggplot(aes(x=time,y=temp))+geom_line()+facet_wrap(reps~.)
```

# Three Hypothetical Species

Next, we want to simulate TDT curves for three hypothetical species. We can do this by getting three CTmax and three z parameters, and making TDT curves from those parameters. We will demonstrate here a chronic vs. acute tradeoff, with a third mixed strategy species that outperforms both species at extreme acute and chronic durations, but comparatively underperforms for the bulk of durations examined.

```{r,echo=F}
set.seed(123)

#Let's create three species: Two of which have intersecting TDT at 30C and 15 days. The third will intersect the high CT species at 30C at 1 day. We will set CTmax.

#first, find potential values of CTmax to work with that intsersect at 15 days at 30C using a loop.
temp.seq<-seq(35,50,by=1) #ctmax options
z_list<-vector("list",length=length(temp.seq))

for (i in 1:length(temp.seq)){
slope<-(log10(15*60*24-1)/(30-temp.seq[i])) #using tdt formula, insert duration and magnitude
z_list[[i]]<-(-1/slope)
}

z_bound<-unlist(z_list)
sim_vals<-data.frame("ctmax"=temp.seq,"z"=z_bound) #candidate ctmax and z values for an intersection

#we select 48C and 44C to start off. looks good. 
highct_highz<-sim_vals[14,]
highct_highz$species<-"highct_highz"
lowct_midz<-sim_vals[10,]
lowct_midz$species<-"lowct_midz"

#thus far, we have selected tdt curves that intersect in the middle of our parameter field (15 days, 4C above)
#we now are interested in a species that still has a lower CTmax, but will have a lower z such that it intersects the highCTmax Highz species quickly at 12 hours.

#this function finds the missing CTmax or z values or time to death if one is missing. 
equaltdt <- function(CTmax1, CTmax2, z1, z2, timetodeath) {
  if (is.na(CTmax2)) {
    CTmax2 <- CTmax1 - (log10(timetodeath) * (z1 - z2))
    tempatdeath <- CTmax2 - z2 * log10(timetodeath)
    return(list(CTmax2 = CTmax2, z2 = z2, temp_at_equal_TDT = tempatdeath))
  } else if (is.na(z2)) {
    z2 <- z1 - ((CTmax1 - CTmax2) / log10(timetodeath))
    tempatdeath <- CTmax2 - z2 * log10(timetodeath)
    return(list(z2 = z2, temp_at_equal_TDT = tempatdeath))
  } else if (is.na(timetodeath)) {
    timetodeath<-10^((CTmax1-CTmax2)/(z1-z2))
    tempatdeath <- CTmax2 - z2 * log10(timetodeath)

    return(list(timetodeath=timetodeath,tempatdeath=tempatdeath))
  }
}

#acute-chronic
equ_res1a<-equaltdt(CTmax1=highct_highz$ctmax,CTmax2=lowct_midz$ctmax,z1=highct_highz$z,z2=NA,timetodeath=12*60)

lowct_lowz<-data.frame("ctmax"=44,"z"=equ_res1a$z2,"species"="lowct_lowz")
equ_res1b<-equaltdt(CTmax1=lowct_midz$ctmax,CTmax2=highct_highz$ctmax,z1=lowct_midz$z,z2=highct_highz$z,timetodeath=NA)


#acute-mixed
equ_res2<-equaltdt(CTmax1=lowct_lowz$ctmax,CTmax2=lowct_midz$ctmax,z1=lowct_lowz$z,z2=lowct_midz$z,timetodeath=NA)
#chronic-mixed
equ_res3<-equaltdt(CTmax1=highct_highz$ctmax,CTmax2=lowct_lowz$ctmax,z1=highct_highz$z,z2=lowct_lowz$z,timetodeath=NA)


#set ctmax and z parameters. These are our candidate species. 
example_TDT<-bind_rows(highct_highz,lowct_midz,lowct_lowz)

kable(example_TDT)

#now simulate tdt data

temp<-rep(seq(26,48,by=2))

# Create an empty data frame to store the results
sim_pred <- vector("list",length=nrow(example_TDT))
error<-10^(-1)

# Loop over the species
for(m in 1:nrow(example_TDT)){
  # Model of TDT curve
  time <- 10^((example_TDT$ctmax[m] - temp) / example_TDT$z[m])
  
  fit <- lm(log10(time) ~ temp)

  

  sim_results <- data.frame(species = rep(example_TDT$species[m], length(time)),
                                temp = temp,
                                time = time,
                            geom = "line")
    simulated_data <- data.frame()

    for (j in seq_along(temp)) {
       # Generate 10 replicates for each temperature with normal distribution
       replicates <- data.frame(
         temp = rep(temp[j], times = 10),
         time = 10^(rnorm(10, mean(predict(fit, newdata = data.frame(temp = temp[j]))), sqrt(error)))
       )
         # Add to the simulated_data
       replicates$species <- rep(example_TDT$species[m], nrow(replicates))
       replicates$geom="point"
      simulated_data <- bind_rows(simulated_data, replicates)

    }
  
  sim_pred[[m]] <- rbind(simulated_data, sim_results)
}

sim_pred_bound<-bind_rows(sim_pred)

simulated_line<-sim_pred_bound%>%filter(geom=="line")
simulated_point<-sim_pred_bound%>%filter(geom=="point")

temp.df<-simulated_point%>%select(-"geom")


#we want both examples to have almost no mortality at no MHW
unique_simsp<-unique(sim_pred_bound$species)

models <- by(simulated_point, simulated_point$species, function(sub_df) lm(log10(time) ~ temp, data = sub_df))

    
    
three_species<-ggplot()+
  geom_line(data=simulated_line,aes(x=temp,y=time,color=species),lwd=1)+
  scale_y_log10()+
  geom_point(data=simulated_point,aes(x=temp,y=time,color=species,shape=species),alpha=0.5,size=2)+
  theme_classic()+
  ylab("Time to death (min)")+xlab("Assay Temp. (°C)")+
  scale_color_brewer(name="Species Strategy",
                      labels=c("Acute Tolerator","Chronic Tolerator","Mixed Strategy"),
                      palette="Set1")+  theme(legend.text.align = 0)+
  scale_x_continuous(breaks=seq(26,48,by=4))+
  scale_shape_discrete(name="Species Strategy",
                      labels=c("Acute Tolerator","Chronic Tolerator","Mixed Strategy"))+

  #mixed-acute
    geom_segment(aes(x=25,xend=equ_res1b$tempatdeath,y=equ_res1b$timetodeath,yend=equ_res1b$timetodeath),color="black",linetype="dashed",inherit.aes=F,linewidth=.4)+
  geom_segment(aes(x=equ_res1b$tempatdeath,xend=equ_res1b$tempatdeath,y=0,yend=equ_res1b$timetodeath),color="black",linetype="dashed",inherit.aes=F,linewidth=.4)+
  annotate("text",x=29,y=5000,label=paste0("15 Days, \n" ,equ_res1b$tempatdeath,"°C "),
           size=2.75)+
  geom_point(aes(x=equ_res1b$tempatdeath,y=equ_res1b$timetodeath),shape=21,color="black",fill="white")+
  #chronic-mixed
  geom_segment(aes(x=25,xend=equ_res2$tempatdeath,y=equ_res2$timetodeath,yend=equ_res2$timetodeath),color="black",linetype="dashed",inherit.aes=F,linewidth=.4)+
  geom_segment(aes(x=equ_res2$tempatdeath,xend=equ_res2$tempatdeath,y=0,yend=equ_res2$timetodeath),color="black",linetype="dashed",inherit.aes=F,linewidth=.4)+
  annotate("text",x=42.5,y=0.2,label=paste0("1 Minute,  \n",equ_res2$tempatdeath,"°C "),
           size=2.75)+
    geom_point(aes(x=equ_res2$tempatdeath,y=equ_res2$timetodeath),shape=21,color="black",fill="white")+
  #acute-chronic

  geom_segment(aes(x=25,xend=equ_res3$tempatdeath,y=equ_res3$timetodeath,yend=equ_res3$timetodeath),color="black",linetype="dashed",inherit.aes=F,linewidth=.4)+
  geom_segment(aes(x=equ_res3$tempatdeath,xend=equ_res3$tempatdeath,y=0,yend=equ_res3$timetodeath),color="black",linetype="dashed",inherit.aes=F,linewidth=.4)+
  annotate("text",x=37.5,y=9000,label=paste0(round((equ_res3$timetodeath/24),digits=1)," Hours, \n ",round(equ_res3$tempatdeath,digits=1),"°C "),
           size=2.75)+
      geom_point(aes(x=equ_res3$tempatdeath,y=equ_res3$timetodeath),shape=21,color="black",fill="white")

three_species
ggsave(path = "result_figs",filename="threespecies_TDT.pdf", device='pdf', dpi=300,width=6,height=4,units="in")
ggsave(path = "result_figs",filename="threespecies_TDT.tif", device='tiff', dpi=300,width=6,height=4,units="in")

```

We should check and make sure the CTmax and z estimates from our simulated data make sense (i.e. close to the values we used to simulate the data to begin with). They look pretty good. 

```{r}
ctmaxz_df<-data.frame("species"=rep(NA,3),"z"=rep(NA,3),"z_original"=rep(NA,3),"CTmax"=rep(NA,3),"CTmax_original"=rep(NA,3))

unique_sp<-unique(simulated_point$species)
for (i in 1:length(unique_sp)){
  spi<-simulated_point%>%filter(species==unique_sp[i])
  tl_res<-tolerance.landscape.np(spi$temp,spi$time)
    ctmaxz_df[i,1]<-unique(spi$species)
    ctmaxz_df[i,2]<-tl_res$z
     ctmaxz_df[i,3]<-example_TDT[i,2]
     ctmaxz_df[i,4]<-tl_res$ctmax
     ctmaxz_df[i,5]<-example_TDT[i,1]
  
}

kable(ctmaxz_df)
```

# Three species Heatmap

Now, we can run the simulated TDT curve with the environmental data to get an estimate of mortality for both species

```{r,echo=F,warning=F,eval=F}
####TIME CONSUMING####


#For both hypothetical species, we are only going to look at time series with alpha 0.75
merged_temp_tri<-merged_temp_tri_alphas[[2]]

rm(merged_temp_tri_alphas)
#   user  system elapsed 
#  71.71   60.69 16739  


unique_simsp<-unique(temp.df$species)
final_surv_crosssim_species<-vector("list",length(unique_simsp))
r<-vector("list",length(merged_temp_tri))

cl <- makeCluster(2) #i only use two cores because I run out of machine memory with more. 
registerDoParallel(cl)

sys.tm <- system.time({
  for (yy in 1:length(unique_simsp)) {
    #for each species
    temp.df_sp <- temp.df %>% dplyr::filter(species == unique_simsp[yy])
    #parallelized loop
    results <- foreach::foreach(i = 1:length(merged_temp_tri), .packages = c('dplyr', 'ggplot2'), .combine = 'rbind') %dopar% {
      #rezende_min is my combined function tolerance landsacpe and dynamic model from Rezende 2014. Takes minutes. 
      tmpi <- rezende_min(merged_temp_tri[[i]], temp.df_sp,tc=26)
      temp_plat_rep <- purrr::map_dfr(seq_len(2), ~merged_temp_tri[[i]])
      r_subset <- cbind(tmpi, temp_plat_rep)
      
      r_subset <- r_subset %>% dplyr::filter(type == "cum.mort")
      
      final_surv_crosssim_species_n <- data.frame(
        'cum.mort' = min(na.omit(r_subset$mort)),
        "magnitude" = max(r_subset$magnitude),
        "duration" = max(r_subset$duration),
        "rising_slope" = max(r_subset$rising_slope),
        "falling_slope" = max(r_subset$falling_slope),
        "area" = max(r_subset$area),
        "rep" = max(r_subset$rep),
        "mean_i" = max(r_subset$mean_i),
        "hdd" = max(r_subset$hdd),
        "duration_hob" = max(r_subset$duration_hob),
        "peak_date" = max(r_subset$peak_date),
        "category" = max(r_subset$category),
        "imax_hob" = max(r_subset$imax_hob),
        "p_moderate" = max(r_subset$p_moderate),
        "p_strong" = max(r_subset$p_strong),
        "p_severe" = max(r_subset$p_severe),
        "p_extreme" = max(r_subset$p_extreme),
        "species" = unique_simsp[yy],
        "alpha" = 12.75 #indicates our interannual variation
      )
      
      return(final_surv_crosssim_species_n)
    }
    
    final_surv_crosssim_species[[yy]] <- results
  } # loop for each species
})

parallel::stopCluster(cl)
sys.tm





saveRDS(final_surv_crosssim_species,"data/final_surv_crosssim_species_try.RDs")
#25772 for 2 on personal machine
#3267 for 3 on computing cluster



```

```{r,include=F,warning=F}
#This chunk calculates proportions of mortality factors within categories

final_surv_crosssim_species<-readRDS("data/final_surv_crosssim_species_try.RDs")
final_surv_crosssim_species_bound<-bind_rows(final_surv_crosssim_species)

#remove MHWs that are less than five days
final_surv_crosssim_species_bound<-final_surv_crosssim_species_bound%>%mutate(category=ifelse(duration<(5*24*60),NA,category))


unique_simsp<-unique(temp.df$species)

cats<-unique(final_surv_crosssim_species_bound$category)
category_prop_list<-vector("list",length=length(cats))
category_list_species<-vector("list",length=length(unique_simsp))


for (j in 1:length(unique_simsp)){
  spi<-final_surv_crosssim_species_bound%>%filter(species==unique_simsp[j]) #for each species
for (i in 1:length(cats)){
if (is.na(cats[i])) {
    cati <- spi %>% filter(is.na(category))
  } else {cati <- spi %>% filter(category == cats[i])
  }  
  cati$ceilingmort<-(ceiling(cati$cum.mort/5)*5) #create bins of 5% survival
  cati$ceilingmort_f<-as.factor(cati$ceilingmort)
  unique_ceiling_mort<-unique(cati$ceilingmort_f)
  cati$leveldens<-1/nrow(cati) #density
  category_prop_list[[i]]<-cati
}#category
  category_list_species[[j]]<-category_prop_list
}#species
category_prop_species<-bind_rows(category_list_species)



category_prop_species$category <- ifelse(is.na(category_prop_species$category), "No MHW", category_prop_species$category)

category_prop_species$ceilingmort_f<-factor(category_prop_species$ceilingmort_f,levels=c(seq(max(category_prop_species$ceilingmort),min(category_prop_species$ceilingmort),by=-5))) 

category_prop_species$category<-factor(category_prop_species$category,levels=c("No MHW","I Moderate","II Strong", "III Severe","IV Extreme")) #label 

```

```{r,echo=F,warning=F}



category_prop_species$hours_dur<-category_prop_species$duration/60 #put into hours

category_prop_species$label <- ifelse(category_prop_species$species == "highct_highz", "Acute Tolerator",
                                     ifelse(category_prop_species$species == "lowct_midz", "Mixed Strategy",
                                            "Chronic Tolerator"))

#create limits for rectangles. add/subtract to expand to grid tile outlines rather than middle
category_ribbon <- category_prop_species %>%
  group_by(category) %>%
  summarise(min_magnitude = min(magnitude) - 0.22,
            max_magnitude = max(magnitude) + 0.22,
            min_duration = min(duration)-12*60 ,
            max_duration = max(duration)+12*60)

category_prop_species2<-left_join(category_prop_species,category_ribbon,by='category')

#view colors for each strategy
#RColorBrewer::brewer.pal(3,"Set1")
##Create dataframe to plot intersection point of the mixed-strategy and acute tolerator species
points_data_whole <- data.frame(
  duration = c(15*24, 15*24),
  magnitude = c(30-26, 30-26),
  label = c("Acute Tolerator", "Mixed Strategy"),
  colour = c("#E41A1C", "#4DAF4A"),
  shape = c(1, 0),
  intersection = c("Acute Tolerator-Mixed Strategy")
)



thick_legend<-plot_grid(get_legend(ggplot(category_prop_species,aes(x=hours_dur,y=magnitude,z=cum.mort,group=species))+geom_tile(aes(fill=cum.mort),size=.5)+
  scale_fill_viridis_c()+
  theme_classic()+
  geom_rect(data=category_prop_species2,aes(xmin=min_duration/60,xmax=max_duration/60,ymin=min_magnitude,ymax=max_magnitude,color=category),fill=NA,inherit.aes=F,linewidth=1)+
  #vertical
  geom_segment(aes(x=8.4*12,xend=8.4*12,y=.75-.075,yend=8.27),color="cornsilk3",lwd=1)+
  #horizontal
   geom_segment(aes(x=8.4*12,xend=61*12,y=.75-0.03,yend=.75-0.03),color="cornsilk3",lwd=1)+
  scale_color_manual(values=MHW_colours)+
  geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  labs(color="MHW Category", fill="Survival (%)")+
  xlab("Duration (h)")+facet_wrap(.~label)+
  ylab("Magnitude (°C)")))

heatmap_legend_only<-cowplot::get_legend(ggplot(category_prop_species,aes(x=hours_dur,y=magnitude,z=cum.mort,group=species))+geom_tile(aes(fill=cum.mort),size=.5)+
  scale_fill_viridis_c()+
  theme_classic()+
  geom_rect(data=category_prop_species2,aes(xmin=min_duration/60,xmax=max_duration/60,ymin=min_magnitude,ymax=max_magnitude),fill=NA,inherit.aes=F,linewidth=1)+
  #vertical
  geom_segment(aes(x=8.4*12,xend=8.4*12,y=.75-.075,yend=8.27),color="cornsilk3",lwd=1)+
  #horizontal
   geom_segment(aes(x=8.4*12,xend=61*12,y=.75-0.03,yend=.75-0.03),color="cornsilk3",lwd=1)+
  scale_color_manual(values=MHW_colours)+
  geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  labs( fill="Survival (%)")+
  xlab("Duration (h)")+facet_wrap(.~label)+
  ylab("Magnitude (°C)"))


species_heatmap_plot<-ggplot(category_prop_species2,aes(x=hours_dur,y=magnitude,z=cum.mort,group=species))+geom_tile(aes(fill=cum.mort),size=.5)+
  scale_fill_viridis_c()+
  theme_classic()+
  geom_rect(data=category_prop_species2,aes(xmin=min_duration/60,xmax=max_duration/60,ymin=min_magnitude,ymax=max_magnitude,color=category),fill=NA,inherit.aes=F,linewidth=1)+
  #vertical
  geom_segment(aes(x=8.5*12,xend=8.5*12,y=.75-.075,yend=8.27),color="cornsilk3",lwd=1)+
  #horizontal
   geom_segment(aes(x=8.5*12,xend=61.5*12,y=.75-0.05,yend=.75-0.03),color="cornsilk3",lwd=1)+
  scale_color_manual(values=MHW_colours)+
  geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  labs(color="MHW Category", fill="Survival (%)")+
  xlab("Duration (h)")+facet_wrap(.~label)+
  ylab("Magnitude (°C)")+
  geom_point(data = points_data_whole, aes(x=duration,y=magnitude),fill = c('#E41A1C','#4DAF4A'),color="black",shape = c(24),size=2,inherit.aes=F)+guides(shape="none")


ggsave(path = "result_figs",filename="species_heatmap_three.pdf", device='pdf', dpi=300,width=12,height=4,units="in")
ggsave(path = "result_figs",filename="species_heatmap_three.tif", device='tiff', dpi=300,width=12,height=4,units="in")

species_arranged_plot<-plot_grid(three_species,
                                 species_heatmap_plot,
                                 ncol=1,nrow=2,rel_heights=c(.75,1),labels="AUTO",align="v")


species_arranged_plot
ggsave(path = "result_figs",filename="species_combinedplots_three.tif", device='tiff', dpi=300,width=12,height=8,units="in")
ggsave(path = "result_figs",filename="species_combinedplots_three.pdf", device='pdf', dpi=300,width=12,height=8,units="in")
```

Let's see an example of a magnitude-duration combination resulting in similar mortality

```{r,echo=F}
#connect 10 day and 1 day for acute
same_mort_days<-category_prop_species%>%group_by(species)%>%filter(duration==c(10*60*24+60,3*24*60+60))%>%filter(round(cum.mort,digits=0)==92)
  same_mort_days                                                            


```

Now, let's see how altering the thermal adaptation strategy changes sensitivity to different oceanographic definitions of MHWs.

```{r,echo=F,warning=F}

# Assuming 'category_prop_species' is your data frame
species_list <- unique(category_prop_species$label)

# Create a table for each species
for (i in 1:length(species_list)) {
  cat(paste("Table for", species_list[i], ":\n"))
  cat("------------------------------\n")
  
  # Subset the data for the current species
  subset_data <- subset(category_prop_species, label == species_list[i])
  
  # Create a table for the current species
  result_table <- table(subset_data$category, subset_data$ceilingmort_f)
  
  # Print the table
  print(result_table)
  
  cat("\n\n")
}


#where does minimum inside MHW mortality occur
category_prop_species%>%group_by(species)%>%filter(duration>5*24*60)%>%slice_min(cum.mort)


#where does minimum outside MHW mortality occur
category_prop_species%>%group_by(species)%>%filter(duration<5*24*60)%>%slice_min(cum.mort)

result <- category_prop_species %>%
group_by(ceilingmort_f,category, label) %>%
summarise(total_leveldens = sum(leveldens, na.rm = TRUE))

species_barplot<-result%>%ggplot()+geom_bar(aes(y=total_leveldens,x=category,fill=ceilingmort_f),position='stack',stat='identity')+
  scale_fill_viridis_d(direction=-1)+labs(x="MHW Category",y="Survival Isocline Proportion",fill="Survival Isoclines")+theme_classic()+facet_wrap(.~label)+theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))+guides(fill=guide_legend(ncol=2))

species_barplot

ggsave(path = "result_figs/supp",filename="species_barchart.pdf", device='pdf', dpi=300,width=8,height=4,units="in")
ggsave(path = "result_figs/supp",filename="species_barchart.tif", device='tiff', dpi=300,width=8,height=4,units="in")


```

# All Alphas (Annual variability)

Now, we can look at one 'species' (acute tolerator) and how changing variation changes MHW categories. We will classify MHWs using the three different 90th percentile thresholds we calcualted earlier, at 0.25, 0.75, and 1.5 °C above climatology.

```{r,eval=F,echo=F}
####TIME CONSUMING####

#since changing the internannual variation just changes thresholds, we can re-use the tolerance landscape for the species.

alpha_length<-length(merged_temp_tri_alphas)
alpha_list_short<-c(12.25,12.75,13.5) # our interannual variation combinations
surv_crosssim_alphas<-data.frame( #yes this is ugly but we're rolling with it
        'cum.mort' =rep(NA,times=527),
        "magnitude" = rep(NA,times=527),
        "duration" = rep(NA,times=527),
        "rising_slope" = rep(NA,times=527),
        "falling_slope" = rep(NA,times=527),
        "area" = rep(NA,times=527),
        "rep" = rep(NA,times=527),
        "mean_i" = rep(NA,times=527),
        "hdd" = rep(NA,times=527),
        "duration_hob" = rep(NA,times=527),
        "peak_date" = rep(NA,times=527),
        "category" = rep(NA,times=527),
        "imax_hob" = rep(NA,times=527),
        "p_moderate" = rep(NA,times=527),
        "p_strong" = rep(NA,times=527),
        "p_severe" = rep(NA,times=527),
        "p_extreme" = rep(NA,times=527),
        "species" = rep(NA,times=527),
        "alpha" = rep(NA,times=527))

for (zz in 1:(alpha_length)){

subset_alpha<-merged_temp_tri_alphas[[zz]]
for (i in 1:length(subset_alpha)){
  r_subset<-subset_alpha[[i]]
final_surv_crosssim_species_alphas_n <- data.frame(
        'cum.mort' =final_surv_crosssim_species[[2]][i,1],
        "magnitude" = max(r_subset$magnitude),
        "duration" = max(r_subset$duration),
        "rising_slope" = max(r_subset$rising_slope),
        "falling_slope" = max(r_subset$falling_slope),
        "area" = max(r_subset$area),
        "rep" = max(r_subset$rep),
        "mean_i" = max(r_subset$mean_i),
        "hdd" = max(r_subset$hdd),
        "duration_hob" = max(r_subset$duration_hob),
        "peak_date" = max(r_subset$peak_date),
        "category" = max(r_subset$category),
        "imax_hob" = max(r_subset$imax_hob),
        "p_moderate" = max(r_subset$p_moderate),
        "p_strong" = max(r_subset$p_strong),
        "p_severe" = max(r_subset$p_severe),
        "p_extreme" = max(r_subset$p_extreme),
        "species" = "highct_highz",
        "alpha" = alpha_list_short[zz])
surv_crosssim_alphas[i,]<-final_surv_crosssim_species_alphas_n


}
final_surv_crosssim_alphas[[zz]]<-surv_crosssim_alphas

}



saveRDS(final_surv_crosssim_alphas,"data/final_surv_crosssim_alphas.RDs")
```

```{r,echo=F,eval=F}
merged_temp_tri_alphas<-readRDS("data/merged_temp_tri_alphas.RDs") #reading this file in can take a while

#get a subset of MHW profiles for a conceptual subpanel

alpha_0.25<-bind_rows(merged_temp_tri_alphas[[1]][[5]],#2 deg 60 min
merged_temp_tri_alphas[[1]][[180]],#4 deg 10 days
merged_temp_tri_alphas[[1]][[353]], #6 deg 20 days
merged_temp_tri_alphas[[1]][[527]], #8 deg 30 day
)
alpha_0.25$alpha=0.25

alpha_0.75<-bind_rows(merged_temp_tri_alphas[[2]][[5]],#2 deg 60 min
merged_temp_tri_alphas[[2]][[180]],#4 deg 10 days
merged_temp_tri_alphas[[2]][[353]], #6 deg 20 days
merged_temp_tri_alphas[[2]][[527]], #8 deg 30 day
)
alpha_0.75$alpha=0.75

alpha_1.5<-bind_rows(merged_temp_tri_alphas[[3]][[5]],#2 deg 60 min
merged_temp_tri_alphas[[3]][[180]],#4 deg 10 days
merged_temp_tri_alphas[[3]][[353]], #6 deg 20 days
merged_temp_tri_alphas[[3]][[527]], #8 deg 30 day
)
alpha_1.5$alpha=1.5

rm(merged_temp_tri_alphas)

alpha_concept<-bind_rows(alpha_0.25,alpha_0.75,alpha_1.5)

alpha_concept <- alpha_concept %>%
  mutate(label = case_when(
    alpha == 0.25 ~ "+ 0.25°C",
    alpha == 0.75 ~ "+ 0.75°C",
    alpha == 1.5 ~ "+ 1.5°C"
  ))

saveRDS(alpha_concept,"data/alpha_concept.RDs")
```

```{r,echo=F,warning=F}

alpha_concept<-readRDS("data/alpha_concept.RDs")

alpha_legend<-get_legend(ggplot(data=alpha_concept,aes(x=time,y=temp,group=magnitude))+geom_line()+
  facet_wrap(.~label)+
      geom_line(aes(x=time,y=seas,color="Climatology"),linetype=2,linewidth=1,inherit.aes=F,color="darkgray")+
      geom_line(aes(x=time,y=thresh,color="90% Threshold"),linetype=2,linewidth=1,inherit.aes=F)+
      geom_line(aes(x=time,y=thresh_2x,color="2x Threshold"),linetype=2,linewidth=1,inherit.aes=F)+
      geom_line(aes(x=time,y=thresh_3x,color="3x Threshold"),linetype=2,linewidth=1,inherit.aes=F)+
      geom_line(aes(x=time,y=thresh_4x,color="4x Threshold"),linetype=2,linewidth=1,inherit.aes=F)+
      geom_line(aes(x=time,y=temp,color="Observed Temperature"),inherit.aes=F,color="black")+
      scale_color_manual(values=c("Climatology"="darkgray","Observed Temperature"="black",
                                  "90% Threshold"=MHW_colours[2][[1]],"2x Threshold"=MHW_colours[3][[1]],"3x Threshold"=MHW_colours[4][[1]],
                                  "4x Threshold"=MHW_colours[5][[1]]),
                        breaks = c("90% Threshold", "2x Threshold", "3x Threshold", "4x Threshold", "Observed Temperature","Climatology"))+
      
      theme_classic()+labs(x="Time",y="Temperature (°C)",,color="MHW Threshold")+
        geom_blank(aes(color="Climatology"))+
      geom_blank(aes(fill="Observed Temperature",value="black"))+
        #guides(fill="none")+
        theme(axis.title.x=element_blank()))
##########################################
alpha_plasma_leg<-get_legend(ggplot(data=alpha_concept,aes(x=time,y=temp))+
  geom_line(aes(group=magnitude,color=magnitude),linewidth=1)+
scale_color_viridis_c(option="plasma",direction = -1)+
    facet_wrap(.~label)+
  labs(x="Date",y="Temperature (°C)",color="Magnitude (°C)")+
  theme_classic()+
  geom_line(aes(x=time,y=thresh),color=MHW_colours[2][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=thresh_2x),color=MHW_colours[3][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=thresh_3x),color=MHW_colours[4][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=thresh_4x),color=MHW_colours[5][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=vals),color="black",inherit.aes = F,lwd=1.5))
#########################################################################
  alpha_concept_plot<-ggplot(data=alpha_concept,aes(x=time,y=temp))+
  geom_line(aes(group=magnitude,color=magnitude),linewidth=1)+
scale_color_viridis_c(option="plasma",direction = -1)+
    facet_wrap(.~label)+
  labs(x="Date",y="Temperature (°C)",color="Magnitude (°C)")+
  theme_classic()+
  geom_line(aes(x=time,y=thresh),color=MHW_colours[2][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=thresh_2x),color=MHW_colours[3][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=thresh_3x),color=MHW_colours[4][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=thresh_4x),color=MHW_colours[5][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=time,y=vals),color="black",inherit.aes = F,lwd=1.5)+theme(legend.position="none")


leg_combined<-plot_grid(alpha_plasma_leg,alpha_legend,ncol=1)
  
alpha_plot_combined<-plot_grid(alpha_concept_plot,leg_combined,ncol=2,rel_widths = c(1,0.4))
#alpha_plot_combined
ggsave(path = "result_figs",filename="alpha_heatmap_three_concept.pdf", device='pdf', dpi=300,width=8,height=6,units="in")
ggsave(path = "result_figs",filename="alpha_heatmap_three_concept.tif", device='tiff', dpi=300,width=8,height=6,units="in")
```


```{r,include=F}
#Below, Assign survival to bins, and assign to categories
final_surv_crosssim_alphas<-readRDS("data/final_surv_crosssim_alphas.RDs")
final_surv_crosssim_alphas_bound<-bind_rows(final_surv_crosssim_alphas)

#remove MHWs that are less than five days
final_surv_crosssim_alphas_bound<-final_surv_crosssim_alphas_bound%>%mutate(category=ifelse(duration<(5*24*60),NA,category))

cats<-unique(final_surv_crosssim_alphas_bound$category)
unique_alphas<-c(12.25,12.75,13.5)

category_prop_list<-vector("list",length=length(cats))
category_prop_list_a<-vector("list",length=length(unique_alphas))

for (j in 1:length(unique_alphas)){
  spi<-final_surv_crosssim_alphas_bound%>%filter(alpha==unique_alphas[j])
for (i in 1:length(cats)){
if (is.na(cats[i])) {
    cati <- spi %>% filter(is.na(category))
  }else{cati <- spi %>% filter(category == cats[i])
  }

  if(nrow(cati)>0){
  cati$ceilingmort<-(ceiling(cati$cum.mort/5)*5) # 5% breaks
  cati$ceilingmort_f<-as.factor(cati$ceilingmort)
  unique_ceiling_mort<-unique(cati$ceilingmort_f)
  cati$leveldens<-1/nrow(cati)

  category_prop_list[[i]]<-cati
  }
}
  category_prop_list_a[[j]]<-category_prop_list
}

category_prop_alphas<-bind_rows(category_prop_list_a)


category_prop_alphas$category <- ifelse(is.na(category_prop_alphas$category), "No MHW",category_prop_alphas$category)

category_prop_alphas$category<-factor(category_prop_alphas$category,levels=c("No MHW","I Moderate","II Strong", "III Severe","IV Extreme")) 

category_prop_alphas$ceilingmort_f<-factor(category_prop_alphas$ceilingmort_f,levels=c(seq(max(category_prop_alphas$ceilingmort),min(category_prop_alphas$ceilingmort),by=-5))) 



```

```{r,echo=F}

category_prop_alphas$hour_dur<-category_prop_alphas$duration/60
category_prop_alphas$species<-"High CT, Low z"

# Create a new column 'label'
category_prop_alphas <- category_prop_alphas %>%
  mutate(label = case_when(
    alpha == 12.25 ~ "+ 0.25°C",
    alpha == 12.75 ~ "+ 0.75°C",
    alpha == 13.5 ~ "+ 1.5°C"
  ))

category_prop_alphas <- category_prop_alphas %>%
  mutate(nomhw = case_when(
    alpha == 12.25 ~ 0.25,
    alpha == 12.75 ~ 0.75,
    alpha == 13.5 ~ 1.25
  ))


#create limits for rectangles. add/subtract to expand to grid tile outlines rather than middle
category_ribbon_alphas <- category_prop_alphas %>%
  group_by(category,alpha) %>%
  summarise(min_magnitude = min(magnitude) - 0.21,
            max_magnitude = max(magnitude) + 0.21,
            min_duration = min(duration)-12*60 ,
            max_duration = max(duration)+12*60)

category_prop_alphas2<-left_join(category_prop_alphas,category_ribbon_alphas,by=c('category','alpha'))

facet_hlines <- category_prop_alphas2 %>%
  distinct(nomhw, label)
#now, we need to create a dataframe that assigns the 'upper right corner' of gray rectangle, i.e. the threshold beyond which Hobday starts assigning heatwaves

thresh_alpha_hob<-data.frame("alpha"=c(rep(unique(category_prop_alphas2$alpha))),
                             "vertical_hobday_threshold_x"=rep(8.5*12,times=3),
                             "vertical_hobday_threshold_xend"=rep(8.5*12,times=3),
                             "vertical_hobday_threshold_y"=c(.25-0.074,.75-.077,1.5-.29),
                             "vertical_hobday_threshold_yend"=c(8.27,8.27,8.27),
                             "horizontal_hobday_threshold_x"=rep(8.2*12,times=3),
                             "horizontal_hobday_threshold_xend"=rep(61.4*12,times=3),
                             "horizontal_hobday_threshold_y"=c(.25-0.02,.75-0.04,1.5-.27),
                             "horizontal_hobday_threshold_yend"=c(.25-0.02,.75-0.04,1.5-0.27)
                             )

                       

category_prop_alphas2<-left_join(category_prop_alphas2,thresh_alpha_hob,by=c('alpha'))

alpha_heatmap_leg<-get_legend(ggplot(category_prop_alphas2,aes(x=hour_dur,y=magnitude,z=cum.mort,group=species))+geom_tile(aes(fill=cum.mort),size=.5)+
  scale_fill_viridis_c()+
  theme_classic()+
  geom_rect(data=category_prop_alphas2,aes(xmin=min_duration/60,xmax=max_duration/60,ymin=min_magnitude,ymax=max_magnitude,color=category),fill=NA,inherit.aes=F,linewidth=1)+
  #vertical
  geom_segment(aes(x=vertical_hobday_threshold_x,xend=vertical_hobday_threshold_xend,y=vertical_hobday_threshold_y,yend=vertical_hobday_threshold_yend),color="cornsilk3",lwd=1)+
  #horizontal
  geom_segment(aes(x=horizontal_hobday_threshold_x,xend=horizontal_hobday_threshold_xend,y=horizontal_hobday_threshold_y,yend=horizontal_hobday_threshold_yend),color="cornsilk3",lwd=1)+  scale_color_manual(values=MHW_colours)+
  geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  labs(color="MHW Category", fill="Survival (%)")+
  xlab("Duration (h)")+facet_wrap(.~label)+
  ylab("Magnitude (°C)"))



annual_var_heatmap_plot_noleg<-ggplot(category_prop_alphas2,aes(x=hour_dur,y=magnitude,z=cum.mort,group=species))+geom_tile(aes(fill=cum.mort),size=.5)+
  scale_fill_viridis_c()+
  theme_classic()+
  geom_rect(data=category_prop_alphas2,aes(xmin=min_duration/60,xmax=max_duration/60,ymin=min_magnitude,ymax=max_magnitude,color=category),fill=NA,inherit.aes=F,linewidth=1)+
  #vertical
  geom_segment(aes(x=vertical_hobday_threshold_x,xend=vertical_hobday_threshold_xend,y=vertical_hobday_threshold_y,yend=vertical_hobday_threshold_yend),color="cornsilk3",lwd=1)+
  #horizontal
  geom_segment(aes(x=horizontal_hobday_threshold_x,xend=horizontal_hobday_threshold_xend,y=horizontal_hobday_threshold_y,yend=horizontal_hobday_threshold_yend),color="cornsilk3",lwd=1)+  scale_color_manual(values=MHW_colours)+
  geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  labs(color="MHW Category", fill="Survival (%)")+
  xlab("Duration (h)")+facet_wrap(.~label)+
  ylab("Magnitude (°C)")+theme(legend.position="none")

annual_var_heatmap_plot<-ggplot(category_prop_alphas2,aes(x=hour_dur,y=magnitude,z=cum.mort,group=species))+geom_tile(aes(fill=cum.mort),size=.5)+
  scale_fill_viridis_c()+
  theme_classic()+
  geom_rect(data=category_prop_alphas2,aes(xmin=min_duration/60,xmax=max_duration/60,ymin=min_magnitude,ymax=max_magnitude,color=category),fill=NA,inherit.aes=F,linewidth=1)+
  #vertical
  geom_segment(aes(x=vertical_hobday_threshold_x,xend=vertical_hobday_threshold_xend,y=vertical_hobday_threshold_y,yend=vertical_hobday_threshold_yend),color="cornsilk3",lwd=1)+
  #horizontal
  geom_segment(aes(x=horizontal_hobday_threshold_x,xend=horizontal_hobday_threshold_xend,y=horizontal_hobday_threshold_y,yend=horizontal_hobday_threshold_yend),color="cornsilk3",lwd=1)+  scale_color_manual(values=MHW_colours)+
  geom_contour(color="white")+ geom_text_contour(aes(z = cum.mort),color="white",fontface="bold")+
  labs(color="MHW Category", fill="Survival (%)")+
  xlab("Duration (h)")+facet_wrap(.~label)+
  ylab("Magnitude (°C)")

annual_var_heatmap_plot

ggsave(path = "result_figs",filename="alpha_heatmap_three.tif", device='tiff', dpi=300,width=12,height=4,units="in")
```

```{r,echo=F}
###now, combine heatmap and conceptual figure
complete_alpha_legend<-plot_grid(leg_combined,alpha_heatmap_leg,ncol=1,align="v")

complete_alpha_plot_no_leg<-plot_grid(alpha_concept_plot,
          annual_var_heatmap_plot_noleg,
          ncol=1,nrow=2,rel_heights=1,labels="AUTO",align="v")


alphas_arranged_plot_legend<-plot_grid(complete_alpha_plot_no_leg,complete_alpha_legend,ncol=2,rel_widths=c(1,0.2))
ggdraw(alphas_arranged_plot_legend+theme(plot.background = element_rect(fill = "white", color = NA)))


ggsave(path = "result_figs",filename="annual_var_combined.tif", device='tiff', dpi=300,width=12,height=8,units="in")
```

Now, let's see how altering seasonal variability changes sensitivity to different oceanographic definitions of MHWs.

```{r,echo=F,earning=F}

alphas_list <- unique(category_prop_alphas$label)

# Create a table for each species
for (i in 1:length(alphas_list)) {
  cat(paste("Table for", alphas_list[i], ":\n"))
  cat("------------------------------\n")
  
  # Subset the data for the current species
  subset_data <- subset(category_prop_alphas, label == alphas_list[i])
  
  # Create a table for the current species
  result_table <- table(subset_data$category, subset_data$ceilingmort_f)
  
  # Print the table
  print(result_table)
  
  cat("\n\n")
}

result <- category_prop_alphas %>%
group_by(ceilingmort_f,category, label) %>%
summarise(total_leveldens = sum(leveldens, na.rm = TRUE))

annual_var_barplot<-result%>%ggplot()+geom_bar(aes(y=total_leveldens,x=category,fill=ceilingmort_f),position='stack',stat='identity')+
  scale_fill_viridis_d(direction=-1)+labs(x="MHW Category",y="Survival Isocline Proportion",fill="Survival Isoclines")+theme_classic()+facet_wrap(.~label)+
  #ggtitle("Annual Variation")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

annual_var_barplot

ggsave(path = "result_figs/supp",filename="alpha_barchart.tif", device='tiff', dpi=300,width=8,height=4,units="in")




```

# Seasonality

Now, let's simulate the effect of seasonal occurrence on mortality arising from MHWs. We only look at a single duration (24 days) but the same 17 magnitudes from 0 to 8.

```{r,echo=F,warning=F}

magnitude_min<-0.01 #0.01 degree minimum magnitude. Does not accept 0 value
magnitude_max<-8.01 #8 degree duration max.
duration_min<-24*30*60+60*1 #24 days
duration_max<-24*30*60+60*1 # 24 days

magnitude_inc<-0.5 # magnitudes given in 0.5 degree increments 
duration_inc<-0 #durations given in 0 increment - single duration

season_days<-seq(0,90,by=10)

```

```{r,echo=F,warning=F}

#Make the MHWs

MHW_tri_seasons<-function(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc){
  
  #sequence of magnitudes
  mag_seq<-seq(magnitude_min,magnitude_max,by = magnitude_inc)
  #sequence of duration (in minutes)
  #this is if we want a standard time sequence
  dur_seq<-seq(duration_min,duration_max,by = duration_inc)
  
  #create an expanded dataframe of all possible parameter combinations. 
  expanded<-data.frame(expand.grid('mag_seq'=mag_seq,'dur_seq'=dur_seq))
  
  #create empty matrix to store results
  mag_dur_tri <- vector("list", length(mag_seq))
  
  #single loop to create triangles for each row in the expanded dataframe, encapsulating all possible parameters  
  for (i in 1:nrow(expanded)){
    magnitude<-as.numeric(expanded[i,1])
    hw_length<-expanded[i,2] #duration
    #rising_slope<-expanded[i,3] if we vary slope
    rising_slope<-magnitude/(hw_length/2)
    #create df of dates and numerical sequence
    
    rising_length<-magnitude/rising_slope
    falling_length<-hw_length-rising_length
    if (is.na(rising_length) || is.na(hw_length)) {
      print("Debug: Missing value in rising_length or hw_length")
      #add ifelse to remove unlikely initial slope values
    } else if(rising_length>=hw_length){#if rising portion is longer than entire mhw duration
      z<-data.frame("timestep"=NA,"value"=NA,"magnitude"=magnitude,"duration"=hw_length,"rising_slope"=rising_slope,"falling_slope"=NA,"area"=NA,"mean_i"=NA,"hdd"=NA)

    } else {
      falling_slope<-(-rising_slope)
      #dataframes of rising falling points
      rising_seq<-data.frame("timestep"=seq(1,floor(max(rising_length)),by=1))
      falling_seq<-data.frame("timestep"=seq(from=floor(max(rising_length))+1,to=hw_length,by = 1))
      
      rising_seq$value<-rising_seq$timestep*rising_slope
      falling_seq$value<-(falling_seq$timestep*falling_slope)+(max(rising_length)*magnitude/nrow(falling_seq))+magnitude
      
      #apply values
      
      z<-rbind(rising_seq,falling_seq)
      z$reps<-i
      z$magnitude<-magnitude
      z$duration<-hw_length
      z$rising_slope<-rising_slope
      z$falling_slope<-falling_slope
      z$area<- magnitude*hw_length/2
      z$mean_i<-mean(z$value)
      #heating degree days
      #first, create a column of day 
      if(hw_length<1440){
        z$unique_day<-hw_length
      }else{
        z$unique_day<-(z$timestep-1)%/%1440+1
      }
      
      hdd_tib<-z%>%group_by(unique_day)%>%summarize(mean_t=mean(value))%>%summarize(output=sum(mean_t))
      z$hdd<-hdd_tib$output
    }
    
    
    mag_dur_tri[[i]] <- z
  }
  
  boundoutput_tri<-bind_rows(mag_dur_tri,.id="reps") #from matrix to data.frame
  boundoutput_tri$reps<-as.numeric(boundoutput_tri$reps)

  return(ggplot(data=boundoutput_tri,aes(x=timestep,y=value,group=reps,color=reps))+geom_line()+ theme(legend.position="none")+scale_color_viridis_c())
  
}


system.time(seasonal_tris<-MHW_tri_seasons(magnitude_min,magnitude_max,duration_min,duration_max,magnitude_inc,duration_inc))

tri_data<-seasonal_tris$data
```

```{r,earning=F,echo=F,eval=T}

#Make the Climatology

year_out<-waves('2022-01-01 00:01:00','2022-12-31 00:00:00',alpha=12,beta=14,freq=365*24)

year_thresh<-waves('2022-01-01 00:01:00','2022-12-31 00:00:00',alpha=12.75,beta=14,freq=365*24)


clim<-data.frame("hoy"=lubridate::hour(year_out$datetime) + (lubridate::yday(year_out$datetime) - 1) * 24, #minus one because we are adding hours to
                 "doy"=lubridate::yday(year_out$datetime),
                 "t"=year_out$datetime,
                 "temp"=year_out$vals,
                 "seas"=year_out$vals,
                 "thresh"=year_thresh$vals,
                 "thresh_2x"=(year_thresh$vals-year_out$vals)+year_thresh$vals,
                 "thresh_3x"=(((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals,
                 "thresh_4x"=(((((year_thresh$vals-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)-year_out$vals)+year_thresh$vals)

clim<-clim%>%filter(t>as.POSIXct('2022-07-01 01:00:00'))
out_res<-clim%>%rename("datetime"=t,"vals"=temp)
mintemptime<-out_res%>%filter(datetime>as.POSIXct('2022-07-01 00:00:00'))%>%filter(vals==min(vals))%>%select(datetime)
mintemptime<-as.POSIXct(mintemptime[,1])
reps_list<-unique(tri_data$reps)


```

```{r,echo=F,awrning=F,eval=F}
####TIME CONSUMING####

#join them together

start_day<-as.POSIXct(clim %>% slice_max(temp)%>%pull(t))-lubridate::days(16)
end_day<-as.POSIXct(clim %>% slice_max(temp)%>%pull(t))+lubridate::days(16)

season_days<-seq(0,90,by=10)

merged_temp_tri_seasons<-vector("list",length=length(season_days))
merged_temp_tri_season<-vector("list",length(unique(tri_data$reps)))


system.time(for (k in 1:length(season_days)){
  #fxn to change NA to 0
  start_date_rep<-start_day+lubridate::days(season_days[k])
  end_date_rep<-end_day+lubridate::days(season_days[k])
  
  mid_date_rep<-start_date_rep+lubridate::days(floor(end_date_rep-start_date_rep))/2
  
  for (i in reps_list){
    #setup
    rep_i<-tri_data%>%dplyr::filter(reps==i) # filter for each MHW
    
    start_date_rep<-mid_date_rep-floor(max(rep_i$duration/2))*60-lubridate::hours(1) #find halfway point and subtract from maximum annual timestamp to give start time
    end_date_rep<-start_date_rep+ceiling(max(rep_i$duration))*60
    
    rep_i$datetime<-seq(from=as.POSIXct(start_date_rep),length.out=ceiling(max(rep_i$timestep)),by="min")
    
    #much faster method of left_join and na.replace
    system.time(joined_df<-as.data.table(rep_i)[as.data.table(out_res),on='datetime'])
    system.time(f_dowle3(joined_df))

    joined_df<-as.data.frame(joined_df)
    joined_df$combined_temperature <- joined_df$vals + joined_df$value
    joined_df_short<-joined_df
    joined_df_short<-joined_df_short%>%rename("t"=datetime,"temp"=combined_temperature)
    

    events<-detect_event_hour(joined_df_short,date_start=season_start_dates[k],date_end=season_end_dates[k])
    event_categories<-heatwaveR::category(events,S=F,name="simulation")
    
    #because the thresholds are not smoothed function, we occasionally get more than one category. Fix if so. 
    if (nrow(event_categories)>1){
      event_categories<-event_categories%>%slice(which.max(duration))
    }
    
    joined_df_short$duration_hob<-event_categories$duration
    joined_df_short$peak_date<-mid_date_rep
    joined_df_short$category<-event_categories$category
    joined_df_short$imax_hob<-event_categories$i_max
    joined_df_short$p_moderate<-event_categories$p_moderate
    joined_df_short$p_strong<-event_categories$p_strong
    joined_df_short$p_severe<-event_categories$p_severe
    joined_df_short$p_extreme<-event_categories$p_extreme
    joined_df_short$days_past_peak<-season_days[k]
    
    merged_temp_tri_season[[i]]<-joined_df_short
  }
  
  merged_temp_tri_season<-purrr::compact(merged_temp_tri_season)
  saveRDS(object = merged_temp_tri_season, file = paste0("data/season_mhw_stacks/mhw_stack",k,".Rds"))
  #not saved on github

}
)


```

```{r,echo=F,warning=F,eval=F}
####TIME CONSUMING####

season_days<-seq(0,90,by=10)

#Get survival from the paired climatology and MHWs

sp_filtered<-temp.df%>%filter(species=="highct_highz")


season_cont_result_mort<-data.frame(
  'cum.mort' = NA,
  "magnitude" = NA,
  "duration" = NA,
  "rising_slope" = NA,
  "falling_slope" = NA,
  "area" = NA,
  "rep" = NA,
  "mean_i" = NA,
  "hdd" = NA,
  "duration_hob" = NA,
  "peak_date" = NA,
  "category" = NA,
  "imax_hob" = NA,
  "p_moderate" = NA,
  "p_strong" = NA,
  "p_severe" = NA,
  "p_extreme" = NA,
  "species" = NA,
  "alpha" = NA,
  "season"=NA,
  "dayspostpeak")

season_cont_result<-vector("list",length=length(season_days))
season_cont_result_mort<-vector("list",length=17)

for (i in 1:length(season_days)){
mhw_stack<-readRDS(paste0("data/season_mhw_stacks/mhw_stack",i,".RDs"))

for (k in 1:length(mhw_stack)){
stacki<-mhw_stack[[k]][-c(262081:263520),]
stacki$t<-as.POSIXct(stacki$t, format = "%Y-%m-%d %H:%M:%S", origin = "1970-01-01")
# Now, you can use the ggplot code
stacki$time<-stacki$t
tmpi <- rezende_min(stacki, sp_filtered,tc=26)
temp_stack <- purrr::map_dfr(seq_len(2), ~stacki)
r_subset <- cbind(tmpi, temp_stack)

r_subset <- r_subset %>% dplyr::filter(type == "cum.mort")

final_surv_crosssim_season_n <- data.frame(
  'cum.mort' = min(na.omit(r_subset$mort)),
  "magnitude" = max(r_subset$magnitude),
  "duration" = max(r_subset$duration),
  "rising_slope" = max(r_subset$rising_slope),
  "falling_slope" = max(r_subset$falling_slope),
  "area" = max(r_subset$area),
  "rep" = max(r_subset$rep),
  "mean_i" = max(r_subset$mean_i),
  "hdd" = max(r_subset$hdd),
  "duration_hob" = max(r_subset$duration_hob),
  "peak_date" = as.POSIXct(max(r_subset$peak_date)),
  "category" = unique(r_subset$category),
  "imax_hob" = max(r_subset$imax_hob),
  "p_moderate" = max(r_subset$p_moderate),
  "p_strong" = max(r_subset$p_strong),
  "p_severe" = max(r_subset$p_severe),
  "p_extreme" = max(r_subset$p_extreme),
  "species" = "highct_highz",
  "alpha" = 12.75,
  "season"=as.POSIXct(start_day,origin='1970-01-01 00:00:00')+lubridate::days(season_days[i]),
  "dayspostpeak"=season_days[i])
   
season_cont_result_mort[[k]]<-final_surv_crosssim_season_n

}
season_cont_result_mort2<-bind_rows(season_cont_result_mort)
season_cont_result[[i]]<-season_cont_result_mort
}

season_cont_result<-bind_rows(season_cont_result)

saveRDS(season_cont_result,"data/season_cont_result_mort.RDs")


```

```{r,echo=F,warning=F}

season_cont_result<-readRDS('data/season_cont_result_mort.RDs')

season_cont_result$cum.mort<-season_cont_result$cum.mort/100

season_cont_result$peak_date<-as.POSIXct(season_cont_result$peak_date)

surv_plot<-ggplot(data=season_cont_result,aes(x=peak_date,y=cum.mort,group=magnitude,color=magnitude))+
  geom_line()+
  geom_point()+
  #scale_color_gradient2(low="dodgerblue",high="tomato3",mid="goldenrod",midpoint=4)+
  scale_color_viridis_c(option="plasma",direction=-1)+
  theme_classic()+labs(y="Survival Proportion",x="Date of MHW Peak",color="Magnitude (°C)")+
  scale_x_datetime(date_breaks="month",date_labels="%b",limits=c(as.POSIXct('2022-08-01'),as.POSIXct('2022-11-30')))

surv_plot
#ggsave(path = "result_figs",filename="seasonal_mhw_placement.pdf", device='pdf', dpi=300,width=6,height=4,units="in")


```

```{r,echo=F,warning=F,eval=F}
####TIME CONSUMING####

#Get seasonal occurrence timeseries plot - reduce to hours for computational reasons

#Let's try something different for speed - adjusting each MHW to the timeseries rather than adding them together
maxtemptime <- out_res %>%
  filter(datetime > as.POSIXct('2022-07-01 00:00:00', tz = "UTC")) %>%
  filter(vals == max(vals)) %>%
  select(datetime) %>%
  pull()

reps_list<-unique(tri_data$reps)
clim$t<-as.POSIXct(clim$t,tz="UTC")


singleseason<-vector("list",length=length(reps_list))
allseasons<-vector("list",length=length(season_days))



for (i in 1:length(season_days)){
  add_days<-season_days[i]
  for (j in reps_list){
    #setup
    rep_i<-tri_data%>%dplyr::filter(reps==j) # filter for each MHW
    start_time <- lubridate::force_tz(maxtemptime + lubridate::days(add_days) - (lubridate::minutes(max(rep_i$duration) / 2)),tz="UTC")
    end_time <- lubridate::force_tz(
      maxtemptime + lubridate::days(add_days) + (lubridate::minutes(max(rep_i$duration) / 2))-lubridate::minutes(1)
      ,tz="UTC")
  
    

    rep_i$datetime <- seq(start_time,end_time,by = "min")
      
    
    clim2<-clim%>%rename("datetime"="t","clim_temp"="temp")
    merged_temps<-merge(clim2,rep_i,by=('datetime'))
    merged_temps$merged_temp<-merged_temps$value+merged_temps$clim_temp
    merged_temps$season_day<-as.factor(add_days)
    singleseason[[j]]<-merged_temps
    }
  allseasons[[i]]<-singleseason
}
allseasons_bound<-bind_rows(allseasons)
allseasons_bound_hour<-allseasons_bound %>%
  mutate(hour = format(datetime, "%Y-%m-%d %H:00")) %>%
  group_by(hour) %>%
  filter(datetime == min(datetime))

saveRDS(allseasons_bound_hour,"data/allseasons_bound.RDs")


```

```{r,echo=F,warning=F}

allseasons_bound_hour<-readRDS("data/allseasons_bound.RDs")

maxtemptime <- out_res %>%
  filter(datetime > as.POSIXct('2022-07-01 00:00:00', tz = "UTC")) %>%
  filter(vals == max(vals)) %>%
  select(datetime) %>%
  pull()


alignment_points<-data.frame("datetime"=maxtemptime + lubridate::days(season_days))
alignment_points_df<-left_join(alignment_points,allseasons_bound_hour)

#creates legend
occ_plot<-ggplot(data=allseasons_bound_hour)+
  labs(x="Date",y="Temperature (°C)",color="MHW Threshold")+
  theme_classic()+
  geom_line(aes(x=datetime,y=thresh,color="I Moderate"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_2x,color="II Strong"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_3x,color="III Severe"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_4x,color="IV Extreme"),linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=clim_temp,color="Climatology"),inherit.aes = F)+
  scale_color_manual(values=MHW_colours)

mhwcat.legend<-get_legend(occ_plot)

#actual plot of MHW seasonal occurence
occ_plot2<-ggplot(data=allseasons_bound_hour,aes(x=datetime,y=merged_temp))+
  geom_line(aes(group=interaction(season_day,magnitude),color=magnitude),alpha=0.5,linewidth=1)+
scale_color_viridis_c(option="plasma",direction = -1)+

  labs(x="Date",y="Temperature (°C)",color="Magnitude (°C)")+
  theme_classic()+
  geom_line(aes(x=datetime,y=thresh),color=MHW_colours[2][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_2x),color=MHW_colours[3][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_3x),color=MHW_colours[4][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=thresh_4x),color=MHW_colours[5][[1]],linetype=2,linewidth=1,inherit.aes = F)+
  geom_line(aes(x=datetime,y=clim_temp),color="black",inherit.aes = F)+
  geom_point(data=alignment_points_df,aes(x=datetime,y=clim_temp),color="black",fill="white",inherit.aes=F,shape=21)


#grab that legend
occ.legend<-get_legend(occ_plot2)
  

occ_plot2

#remove legends that are duplicative
occ_arranged_plot<-plot_grid(occ_plot2+theme(legend.position="none"),
                             surv_plot+theme(legend.position="none"),
                                 ncol=1,nrow=2,rel_heights=1,labels="AUTO",align="v")

#combined legend we want
legend_occ_combined<-plot_grid(mhwcat.legend,occ.legend,nrow=2,align="hv")
occ_arranged_plot_legend<-plot_grid(occ_arranged_plot,legend_occ_combined,ncol=2,rel_widths=c(1,0.4),scale=c(1,0.75))
#remove artifacts around legends
ggdraw(occ_arranged_plot_legend+theme(plot.background = element_rect(fill = "white", color = NA)))

ggsave(path = "result_figs",filename="timeseries_survprop.pdf", device='pdf', dpi=300,width=6,height=8,units="in")
ggsave(path = "result_figs",filename="timeseries_survprop.tif", device='tiff', dpi=300,width=6,height=8,units="in")

```

Below we see how the seasonal occurrence of a MHW impacts cumulative survival at the end of each MHW across magnitudes

```{r,echo=F,warning=F,eval=T}

#categories along season

#first, what is the baseline temperature each seasonal placement?
peak_dates<-as.POSIXct(unique(season_cont_result$peak_date))
#create blank df for results
baseline_datevals<-data.frame("val"=rep(NA,length(peak_dates)),"datetime"=rep(NA,length(peak_dates)))
#extract temperature from climatology at each timepoint
for (i in 1:length(peak_dates)){
baseline_val<-year_out%>%filter(datetime==peak_dates[i])
baseline_datevals[i,1]<-baseline_val
baseline_datevals[i,2]<-as.POSIXct(peak_dates[i])
}
baseline_datevals$val<-round(baseline_datevals$val,digits=1)
baseline_datevals$datetime<-as.POSIXct(baseline_datevals$datetime,origin='1970-01-01 00:00:00')
######################
#remove MHWs that are less than five days
season_cont_result<-season_cont_result%>%mutate(category=ifelse(duration<(5*24*60),NA,category))


unique_season<-unique(season_cont_result$season)

cats<-unique(season_cont_result$category)
category_prop_list<-vector("list",length=length(cats))
category_list_season<-vector("list",length=length(unique_season))


for (j in 1:length(unique_season)){
  seasi<-season_cont_result%>%filter(season==unique_season[j])
  for (i in 1:length(cats)){
    if (is.na(cats[i])) {
      cati <- seasi %>% filter(is.na(category))
    } else {cati <- seasi %>% filter(category == cats[i])
    }  
    cati$ceilingmort<-(round(cati$cum.mort/0.05)*0.05)*100
    cati$ceilingmort_f<-as.factor(cati$ceilingmort)
    unique_ceiling_mort<-unique(cati$ceilingmort_f)
    cati$leveldens<-if(nrow(cati)==0){}else{1/nrow(cati)}
    category_prop_list[[i]]<-cati
  }#category
  category_list_season[[j]]<-category_prop_list
}#species
category_prop_season<-bind_rows(category_list_season)

category_prop_season <- category_prop_season %>%
  mutate(category = ifelse(is.na(category), "No MHW", category))


category_prop_season$category<-factor(category_prop_season$category,
                                      levels=c("No MHW","I Moderate","II Strong", "III Severe","IV Extreme")) 



comparison<-category_prop_season %>%
  group_by(dayspostpeak , category,ceilingmort) %>%
  summarise(count = n()) %>%
  group_by(dayspostpeak ,category) %>%
  mutate(proportion = count / sum(count))



saveRDS(comparison,"data/category_prop_season.RDs")
```

```{r,echo=F,warning=F}

comparison<-readRDS("data/category_prop_season.RDs")

comparison_short<-comparison%>%filter(dayspostpeak<=70)

comparison_short$ceilingmort<-as.factor(comparison_short$ceilingmort)

new_labels <- c("0" = "Summer Peak", "10" = "10 days post peak", "20" = "20 days post peak", "30" = "30 days post peak",
                "40"="40 days post peak","50"="50 days post peak","60"="60 days post peak","70"="70 days post peak",
                "80"="80 days post peak","90"="90 days postpeak")
#put baseline temperature onto label
for (i in 1:length(new_labels)){
  new_labels[i]<-paste0(new_labels[i],", ",baseline_datevals[i,1],"°C")
}

occ_barplot<-ggplot(data=comparison_short,aes(x=category,y=proportion,fill=ceilingmort))+
  geom_bar(stat='identity',position = position_fill(reverse = TRUE))+facet_wrap(dayspostpeak ~.,labeller = labeller(dayspostpeak = new_labels),ncol=4)+
  scale_fill_viridis_d()+theme_classic()+
  labs(x="MHW Category",y="Survival Isocline Proportion",fill="Survival Isoclines")+theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))+
  guides(fill = guide_legend(reverse=TRUE))

occ_barplot

ggsave(path = "result_figs/supp","seasonal_occ_barplot.pdf",device="pdf",width=12,height=8,units=c("in")) 
ggsave(path = "result_figs/supp","seasonal_occ_barplot.tif",device="tiff",width=12,height=8,units=c("in"))  


```

# Citations


